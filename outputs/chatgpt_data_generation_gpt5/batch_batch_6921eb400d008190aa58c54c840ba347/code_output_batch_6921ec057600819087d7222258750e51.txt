{"id": "batch_req_6921ec38bd3081909070c9a9af6f2c0b", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "4bec088b7485c5ecc485f7d321313f9a", "body": {"id": "resp_0baac54b2af81267006921ec0b192881a2a32fd4875dcbbf89", "object": "response", "created_at": 1763830795, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0baac54b2af81267006921ec0b5eac81a2807303975357f0ba", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Access statistics and averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Access previous decision rate (must be kept in solver)\n  double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Conflict limit condition (lowest priority)\n  bool conflict_limit = (CONFLICTS >= solver->limits.restart.conflicts);\n\n  // Glue gap condition (highest priority)\n  bool glue_gap = (fast_glue >= slow_glue + 2.0);\n\n  // Decision rate drop condition (middle priority)\n  bool rate_drop = (decision_rate < 0.8 * prev_decision_rate);\n\n  bool triggered = false;\n\n  if (glue_gap) {\n    kissat_extremely_verbose (solver,\n      \"restart: fast glue %.2f >= slow glue %.2f + 2.0 (%.2f), restarting\",\n      fast_glue, slow_glue, slow_glue + 2.0);\n    triggered = true;\n  } else if (rate_drop) {\n    kissat_extremely_verbose (solver,\n      \"restart: decision rate %.4f < 0.8 * previous decision rate %.4f (%.4f), restarting\",\n      decision_rate, prev_decision_rate, 0.8 * prev_decision_rate);\n    triggered = true;\n  } else if (conflict_limit) {\n    kissat_extremely_verbose (solver,\n      \"restart: reached conflict limit %ld >= %ld, restarting\",\n      (long) CONFLICTS, (long) solver->limits.restart.conflicts);\n    triggered = true;\n  }\n\n  if (triggered)\n    solver->previous_decision_rate_ewma = decision_rate;\n\n  return triggered;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 440, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1214}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38ba4c8190a3783ee5f4e1e069", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "e2d3790055cc511b2a9a14475501aacd", "body": {"id": "resp_041344766e9d13b8006921ec0a934481a0a63f76e6fe4a06fd", "object": "response", "created_at": 1763830794, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_041344766e9d13b8006921ec0ac5e081a097f730f1216a5049", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // retrieve and initialize previous_decision_rate_ewma\n  double prev_decision_rate;\n  if (!solver->previous_decision_rate_initialized) {\n    prev_decision_rate = decision_rate;\n    solver->previous_decision_rate_ewma = decision_rate;\n    solver->previous_decision_rate_initialized = true;\n  } else {\n    prev_decision_rate = solver->previous_decision_rate_ewma;\n  }\n\n  bool restart = false;\n\n  // Condition 1: Glue gap\n  if (fast_glue >= slow_glue + 2.0) {\n    restart = true;\n  }\n  // Condition 2: Decision rate drop, only if condition 1 not met\n  else if (decision_rate < 0.8 * prev_decision_rate) {\n    restart = true;\n  }\n  // Condition 3: Conflict limit, lowest priority\n  else if (CONFLICTS >= solver->limits.restart.conflicts) {\n    restart = true;\n  }\n\n  if (restart) {\n    solver->previous_decision_rate_ewma = decision_rate;\n  }\n\n  return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 331, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1105}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38b8108190954f04ca752ad24a", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "8394178aee2231c54842ee51f3a2c097", "body": {"id": "resp_0efeb44b1cafc571006921ec103ae8819cbe1231437c20a62b", "object": "response", "created_at": 1763830800, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0efeb44b1cafc571006921ec107ea0819cbb91d29d00afac6f", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Fetch current conflict count and restart conflict limit\n  const uint64_t conflicts = solver->statistics.conflicts;\n  const uint64_t conflict_limit = solver->limits.restart.conflicts;\n\n  // Fetch moving averages for glue and decision rate\n  const double fast_glue = solver->averages[solver->stable].fast_glue.value;\n  const double slow_glue = solver->averages[solver->stable].slow_glue.value;\n  const double curr_decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // Access previous_decision_rate_ewma (must exist in solver struct)\n  double *prev_dr = &solver->previous_decision_rate_ewma;\n  bool should_restart = false;\n\n  // 1. Glue gap condition\n  if (fast_glue >= slow_glue + 2.0) {\n    should_restart = true;\n    kissat_extremely_verbose (solver,\n      \"restart: fast_glue %g >= slow_glue %g + 2.0: triggering restart\",\n      fast_glue, slow_glue);\n  }\n  // 2. Decision rate drop condition\n  else if (curr_decision_rate < 0.8 * (*prev_dr)) {\n    should_restart = true;\n    kissat_extremely_verbose (solver,\n      \"restart: decision_rate %g < 0.8 * prev_decision_rate %g: triggering restart\",\n      curr_decision_rate, *prev_dr);\n  }\n  // 3. Conflict limit condition\n  else if (conflicts >= conflict_limit) {\n    should_restart = true;\n    kissat_extremely_verbose (solver,\n      \"restart: conflicts %lu >= conflict_limit %lu: triggering restart\",\n      conflicts, conflict_limit);\n  }\n\n  // Update previous_decision_rate_ewma on restart\n  if (should_restart)\n    *prev_dr = curr_decision_rate;\n\n  return should_restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 454, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1228}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38be008190a61366aa73e987ea", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "9f2867eb31e3dc5efe86cdccedb9f0e7", "body": {"id": "resp_03dff8baad3e0162006921ec150cf4819d82b3938914053df3", "object": "response", "created_at": 1763830805, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_03dff8baad3e0162006921ec16d17c819d892e004adcf5044f", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Get moving averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Reference to previous decision rate\n  double *prev_decision_rate_ptr = &solver->previous_decision_rate_ewma;\n  const double prev_decision_rate = *prev_decision_rate_ptr;\n\n  // Tie-breaking/prioritization: 1. glue gap, 2. rate drop, 3. conflict limit\n  bool should_restart = false;\n\n  // 1. Glue gap condition (highest priority)\n  if (fast_glue >= slow_glue + 2.0)\n    should_restart = true;\n  // 2. Decision rate drop (second priority)\n  else if (decision_rate < 0.8 * prev_decision_rate)\n    should_restart = true;\n  // 3. Conflict limit (lowest priority)\n  else if (CONFLICTS >= solver->limits.restart.conflicts)\n    should_restart = true;\n\n  if (should_restart)\n  {\n    // Update previous_decision_rate_ewma on each restart\n    *prev_decision_rate_ptr = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 321, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1095}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38bd6c8190a5b064354c9c5681", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "c3ec11643c733af6a5752c6045c8b403", "body": {"id": "resp_08e6e0b46070308c006921ec1ab44081a28490e497ef1eb9a4", "object": "response", "created_at": 1763830810, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_08e6e0b46070308c006921ec1af0c881a2ac211663a438c859", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver)\n{\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Access current statistics and averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n  double *previous_decision_rate = &solver->previous_decision_rate_ewma;\n\n  // 1. Glue gap condition\n  if (fast_glue >= slow_glue + 2.0) {\n    *previous_decision_rate = decision_rate;\n    kissat_extremely_verbose(\n        solver,\n        \"adaptive-hybrid restart: fast_glue (%.2f) >= slow_glue (%.2f) + 2.0, restarting\",\n        fast_glue, slow_glue);\n    return true;\n  }\n\n  // 2. Decision rate drop condition\n  if (decision_rate < 0.8 * (*previous_decision_rate)) {\n    *previous_decision_rate = decision_rate;\n    kissat_extremely_verbose(\n        solver,\n        \"adaptive-hybrid restart: decision_rate (%.6f) < 0.8 * previous_decision_rate (%.6f), restarting\",\n        decision_rate, *previous_decision_rate / 0.8);\n    return true;\n  }\n\n  // 3. Conflict limit fallback\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    *previous_decision_rate = decision_rate;\n    kissat_extremely_verbose(\n        solver,\n        \"adaptive-hybrid restart: conflicts (%\" PRIu64 \") >= restart_conflict_limit (%\" PRIu64 \"), restarting\",\n        CONFLICTS, solver->limits.restart.conflicts);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 412, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1186}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38b8f8819099ce03f0c2c5442e", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "a66119ed42abb1e011b3976338e3df69", "body": {"id": "resp_0787955d97b9a71a006921ec1f3a1881a2931654922f86e969", "object": "response", "created_at": 1763830815, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0787955d97b9a71a006921ec1f75cc81a2ba6a61fcc21c74bd", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Get current statistics and averages\n  const uint64_t conflicts = solver->statistics.conflicts;\n  const uint64_t conflict_limit = solver->limits.restart.conflicts;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // Initialize or retrieve previous_decision_rate_ewma\n  if (!solver->previous_decision_rate_ewma_initialized) {\n    solver->previous_decision_rate_ewma = decision_rate;\n    solver->previous_decision_rate_ewma_initialized = true;\n  }\n\n  // Condition 1: Glue gap\n  if (fast_glue >= slow_glue + 2.0) {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive glue-rate: glue gap restart (fast %g >= slow %g + 2.0)\",\n      fast_glue, slow_glue\n    );\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  // Condition 2: Decision rate drop\n  if (decision_rate < 0.8 * solver->previous_decision_rate_ewma) {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive glue-rate: decision rate drop restart (%g < 0.8 * %g)\",\n      decision_rate, solver->previous_decision_rate_ewma\n    );\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  // Condition 3: Conflict limit\n  if (conflicts >= conflict_limit) {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive glue-rate: conflict limit restart (%\" PRIu64 \" >= %\" PRIu64 \")\",\n      conflicts, conflict_limit\n    );\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  // No restart triggered\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 472, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1246}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38cc708190941ca489058be302", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "26a116de1c4a9c4b812a5b1594490ae3", "body": {"id": "resp_0c598538328a4d61006921ec248234819f9667e49823b7c68b", "object": "response", "created_at": 1763830820, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0c598538328a4d61006921ec24e650819fb298f38bcdd4b5d6", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver)\n{\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Retrieve previous_decision_rate_ewma, stored in solver->previous_decision_rate_ewma\n  // If not initialized, initialize to current decision_rate\n  if (solver->previous_decision_rate_ewma < 0.0)\n    solver->previous_decision_rate_ewma = decision_rate;\n\n  // 1. Glue gap restart\n  if (fast_glue >= slow_glue + 2.0) {\n    kissat_extremely_verbose(solver,\n      \"adaptive restart: fast_glue %.2f >= slow_glue %.2f + 2.0, triggering\",\n      fast_glue, slow_glue);\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  // 2. Decision rate drop\n  if (decision_rate < 0.8 * solver->previous_decision_rate_ewma) {\n    kissat_extremely_verbose(solver,\n      \"adaptive restart: decision_rate %.2f < 0.8 * previous_decision_rate_ewma %.2f, triggering\",\n      decision_rate, solver->previous_decision_rate_ewma);\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  // 3. Conflict limit\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    kissat_extremely_verbose(solver,\n      \"adaptive restart: conflicts %ld >= conflict limit %ld, triggering\",\n      CONFLICTS, solver->limits.restart.conflicts);\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  // No restart condition met\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 444, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1218}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38bcf48190b76ec7cea2af3e56", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "620febfd6ec9a1eec67047f69e6f89d6", "body": {"id": "resp_0113a6bb96afab3a006921ec291f0881a3b76f861eacddb500", "object": "response", "created_at": 1763830825, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0113a6bb96afab3a006921ec29645081a3ac7f7e6ff6c10f00", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Gather relevant averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Pointer to previous_decision_rate_ewma, must be defined in kissat struct\n  double *prev_decision_rate = &solver->previous_decision_rate_ewma;\n  bool restart = false;\n  int reason = 0;\n\n  // 1. Glue gap condition\n  if (fast_glue >= slow_glue + 2.0)\n  {\n    restart = true;\n    reason = 1;\n  }\n  // 2. Decision rate drop condition\n  else if (decision_rate < 0.8 * (*prev_decision_rate))\n  {\n    restart = true;\n    reason = 2;\n  }\n  // 3. Conflict limit condition\n  else if (CONFLICTS >= solver->limits.restart.conflicts)\n  {\n    restart = true;\n    reason = 3;\n  }\n\n  if (restart)\n  {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive glue-rate hybrid restart: reason %d (fast_glue=%.2f, slow_glue=%.2f, dec_rate=%.4f, prev_dec_rate=%.4f, conflicts=%\" PRIu64 \"/%\" PRIu64 \")\",\n      reason, fast_glue, slow_glue, decision_rate, *prev_decision_rate, CONFLICTS, solver->limits.restart.conflicts);\n\n    // Update previous_decision_rate_ewma on every restart\n    *prev_decision_rate = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 412, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1186}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38bed881909a707f98ccf67d89", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "e6a27d588a7d36de7bd569847a1aa94d", "body": {"id": "resp_01cfc68f0a4a9af9006921ec2dd81c81a3bdb2d52bd8be19f6", "object": "response", "created_at": 1763830829, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_01cfc68f0a4a9af9006921ec2e24a481a39ca253e8a491619f", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve or initialize previous_decision_rate_ewma\n  double *prev_decision_rate_ptr = &solver->previous_decision_rate_ewma;\n  if (!isfinite (*prev_decision_rate_ptr))\n    *prev_decision_rate_ptr = decision_rate;\n\n  bool trigger = false;\n\n  // 1. Glue gap condition (highest priority)\n  if (fast_glue >= slow_glue + 2.0)\n    trigger = true;\n  // 2. Decision rate drop condition\n  else if (decision_rate < 0.8 * (*prev_decision_rate_ptr))\n    trigger = true;\n  // 3. Conflict limit condition\n  else if (CONFLICTS >= solver->limits.restart.conflicts)\n    trigger = true;\n\n  if (trigger)\n    *prev_decision_rate_ptr = decision_rate;\n\n  return trigger;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 272, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1046}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec38b9b88190ab3d4187f49086ea", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "7716519be05d5204c1d0c40040d82e39", "body": {"id": "resp_0f4e2da93facca8b006921ec3265388191afee7ca93b8aba1f", "object": "response", "created_at": 1763830834, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0f4e2da93facca8b006921ec32a304819198d7adc6fbc4504b", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Get relevant statistics and averages\n  const uint64_t conflicts = solver->statistics.conflicts;\n  const uint64_t conflict_limit = solver->limits.restart.conflicts;\n  const double fast_glue = solver->averages[solver->stable].fast_glue.value;\n  const double slow_glue = solver->averages[solver->stable].slow_glue.value;\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // Access and initialize previous_decision_rate_ewma, using the solver's restart struct\n  // We assume: solver->restart.previous_decision_rate_ewma is available and initialized\n  double *prev_rate_ptr = &solver->restart.previous_decision_rate_ewma;\n  double prev_decision_rate = *prev_rate_ptr;\n\n  bool restart = false;\n  int fired = 0; // 1=glue, 2=rate, 3=conflict\n\n  // 1. Glue gap: fast_glue >= slow_glue + 2.0\n  if (fast_glue >= slow_glue + 2.0)\n  {\n    restart = true;\n    fired = 1;\n  }\n  // 2. Decision rate drop: decision_rate < 0.8 * previous_decision_rate_ewma\n  else if (decision_rate < 0.8 * prev_decision_rate)\n  {\n    restart = true;\n    fired = 2;\n  }\n  // 3. Conflict limit\n  else if (conflicts >= conflict_limit)\n  {\n    restart = true;\n    fired = 3;\n  }\n\n  if (restart)\n  {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive glue-rate restart: fast_glue=%.2f slow_glue=%.2f prev_decision_rate=%.2f decision_rate=%.2f trigger=%d\",\n      fast_glue, slow_glue, prev_decision_rate, decision_rate, fired);\n\n    // Update previous_decision_rate_ewma only on restart trigger\n    *prev_rate_ptr = decision_rate;\n  }\n\n  return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 774, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 497, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1271}, "user": null, "metadata": {}}}, "error": null}
