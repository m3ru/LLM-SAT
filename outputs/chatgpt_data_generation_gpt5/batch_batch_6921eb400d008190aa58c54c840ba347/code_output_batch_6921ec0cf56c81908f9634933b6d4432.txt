{"id": "batch_req_6921ec5bc1708190a8eb60bb77be0218", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "01b40770557aeb6d9733492da061b593", "body": {"id": "resp_058dbe110829ef27006921ec4c4a848193816ba6321a120772", "object": "response", "created_at": 1763830860, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_058dbe110829ef27006921ec4c8aa481938ad6b45d96f8eb11", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n    assert(solver->unassigned);\n\n    if (!GET_OPTION(restart))\n        return false;\n\n    if (!solver->level)\n        return false;\n\n    if (CONFLICTS < solver->limits.restart.conflicts)\n        return false;\n\n    // Hybrid EWMA Glue-Drop & Adaptive Decision Rate Restart\n\n    const double fast = AVERAGE(fast_glue);\n    const double slow = AVERAGE(slow_glue);\n    const double fast_threshold = 0.98 * slow;\n\n    const double decision_rate = AVERAGE(decision_rate);\n\n    // Use the solver->restart.prev_decision_rate_ewma for storing previous value\n    double prev_decision_rate = solver->restart.prev_decision_rate_ewma;\n\n    bool glue_trigger = (fast >= fast_threshold);\n    bool decision_rate_trigger = (decision_rate < 0.85 * prev_decision_rate);\n\n    // Update prev_decision_rate_ewma after checking both conditions\n    solver->restart.prev_decision_rate_ewma = decision_rate;\n\n    if (glue_trigger) {\n        kissat_extremely_verbose(solver,\n            \"restarting due to glue EWMA: fast_glue %.2f >= 0.98 * slow_glue %.2f\",\n            fast, slow);\n        return true;\n    } else if (decision_rate_trigger) {\n        kissat_extremely_verbose(solver,\n            \"restarting due to decision rate: decision_rate %.4f < 0.85 * prev_decision_rate %.4f\",\n            decision_rate, prev_decision_rate);\n        return true;\n    }\n\n    return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 353, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1131}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bc714819097f286ad929532f6", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "919bc2e0a7d99c09c3f0d58a378c07d2", "body": {"id": "resp_0923fab4df462cd1006921ec4ca67c8190937e4914da86b4cb", "object": "response", "created_at": 1763830860, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0923fab4df462cd1006921ec4d3a748190af295d5b8bb11a73", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // EWMA values\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision_rate_ewma\n  double prev_decision_rate = solver->prev_decision_rate_ewma;\n\n  // Hybrid condition\n  bool glue_trigger = (fast_glue >= 0.98 * slow_glue);\n  bool decision_rate_trigger = (decision_rate < 0.85 * prev_decision_rate);\n\n  // If either trigger fires, restart\n  if (glue_trigger || decision_rate_trigger) {\n    // Only update prev_decision_rate_ewma after each check\n    solver->prev_decision_rate_ewma = decision_rate;\n    if (glue_trigger) {\n      kissat_extremely_verbose (solver,\n        \"restarting: fast_glue %.2f >= 0.98 * slow_glue %.2f\",\n        fast_glue, slow_glue);\n    } else {\n      kissat_extremely_verbose (solver,\n        \"restarting: decision_rate %.6f < 0.85 * prev_decision_rate %.6f\",\n        decision_rate, prev_decision_rate);\n    }\n    return true;\n  }\n\n  // Always update prev_decision_rate_ewma after checking\n  solver->prev_decision_rate_ewma = decision_rate;\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 375, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1153}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bc358819086b9c3f1c5d953fe", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "c2d8e18e9c54d0590f48a9b7e9350031", "body": {"id": "resp_0e23b9d9bed5973a006921ec4fce888197add181ebbbe8210f", "object": "response", "created_at": 1763830863, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0e23b9d9bed5973a006921ec502eac819796fa66cbe620b9c1", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double glue_threshold = 0.98 * slow_glue;\n\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Use per-solver context for previous decision rate EWMA\n  double *prev_decision_rate_ptr = &solver->prev_decision_rate_ewma;\n  // If this is the first time, initialize\n  if (isnan(*prev_decision_rate_ptr))\n    *prev_decision_rate_ptr = decision_rate;\n\n  const double decision_rate_threshold = 0.85 * (*prev_decision_rate_ptr);\n\n  bool glue_restart = (fast_glue >= glue_threshold);\n  bool decision_rate_restart = (decision_rate < decision_rate_threshold);\n\n  if (glue_restart || decision_rate_restart) {\n    // Prioritize glue trigger in verbose output\n    if (glue_restart) {\n      kissat_extremely_verbose (solver,\n        \"restart triggered by glue: fast_glue %.2f >= %.2f (0.98 * slow_glue %.2f)\",\n        fast_glue, glue_threshold, slow_glue);\n    } else {\n      kissat_extremely_verbose (solver,\n        \"restart triggered by decision rate: decision_rate %.6f < %.6f (0.85 * prev_decision_rate_ewma %.6f)\",\n        decision_rate, decision_rate_threshold, *prev_decision_rate_ptr);\n    }\n    // Update previous decision rate EWMA after check\n    *prev_decision_rate_ptr = decision_rate;\n    return true;\n  }\n\n  // Update previous decision rate EWMA after check (no restart)\n  *prev_decision_rate_ptr = decision_rate;\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 441, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1219}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bc9608190b7fe2fea744b6aad", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "a90fb4d39ae1b480a8c8c9083b6b9a05", "body": {"id": "resp_017226e54a9ae482006921ec4d26b08195a929d7f5ed63a58a", "object": "response", "created_at": 1763830861, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_017226e54a9ae482006921ec4de59c81959364615dc118dc2b", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n    assert (solver->unassigned);\n    if (!GET_OPTION (restart))\n        return false;\n    if (!solver->level)\n        return false;\n    if (CONFLICTS < solver->limits.restart.conflicts)\n        return false;\n\n    // Always run reluctant in stable mode\n    if (solver->stable)\n        return kissat_reluctant_triggered (&solver->reluctant);\n\n    // Retrieve moving averages\n    const double fast_glue = AVERAGE (fast_glue);\n    const double slow_glue = AVERAGE (slow_glue);\n    const double decision_rate = AVERAGE (decision_rate);\n\n    // Access previous decision rate EWMA (initialize if needed)\n    double prev_decision_rate;\n    if (!solver->adaptive_restart.prev_decision_rate_initialized) {\n        solver->adaptive_restart.prev_decision_rate_ewma = decision_rate;\n        solver->adaptive_restart.prev_decision_rate_initialized = true;\n    }\n    prev_decision_rate = solver->adaptive_restart.prev_decision_rate_ewma;\n\n    // Hybrid EWMA Glue-Drop & Adaptive Decision Rate heuristic\n    const double glue_margin = 0.98;\n    const double decision_drop = 0.85;\n\n    bool glue_trigger = (fast_glue >= glue_margin * slow_glue);\n    bool decision_trigger = (decision_rate < decision_drop * prev_decision_rate);\n\n    bool restart = false;\n    if (glue_trigger) {\n        restart = true;\n    } else if (decision_trigger) {\n        restart = true;\n    }\n\n    // Always update prev_decision_rate_ewma after the check\n    solver->adaptive_restart.prev_decision_rate_ewma = decision_rate;\n\n    kissat_extremely_verbose(solver,\n        \"hybrid-glue/decision-restart: fast_glue %g, slow_glue %g (margin %.2f), \"\n        \"decision_rate %g, prev_decision_rate %g (drop %.2f) => %s\",\n        fast_glue, slow_glue, glue_margin, decision_rate, prev_decision_rate, decision_drop,\n        restart ? \"RESTART\" : \"NO-RESTART\");\n\n    return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 471, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1249}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bd05c8190b279e9fc199c799a", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "7c6a07acd4cb53d55501063f50ea3049", "body": {"id": "resp_068553d2e665b522006921ec5413ec8194a84ea01d63023297", "object": "response", "created_at": 1763830868, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_068553d2e665b522006921ec5474108194b6fc0537aa730c57", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // Get averages in current search mode (stable/unstable)\n  const int mode = solver->stable;\n  const double fast_glue_ewma = solver->averages[mode].fast_glue.value;\n  const double slow_glue_ewma = solver->averages[mode].slow_glue.value;\n  const double decision_rate_ewma = solver->averages[mode].decision_rate.value;\n\n  // Use the prev_decision_rate_ewma field (must be initialized elsewhere)\n  double prev_decision_rate_ewma = solver->averages[mode].prev_decision_rate_ewma;\n\n  bool restart = false;\n  const double glue_margin = 0.98;\n  const double dr_margin = 0.85;\n\n  // Prioritize glue-based trigger if both true\n  if (fast_glue_ewma >= glue_margin * slow_glue_ewma) {\n    restart = true;\n    kissat_extremely_verbose (solver,\n      \"hybrid restart: fast glue %.2f >= %.2f * slow glue %.2f (%.2f) [TRUE]\",\n      fast_glue_ewma, glue_margin, slow_glue_ewma, glue_margin * slow_glue_ewma);\n  } else if (decision_rate_ewma < dr_margin * prev_decision_rate_ewma) {\n    restart = true;\n    kissat_extremely_verbose (solver,\n      \"hybrid restart: decision rate %.2f < %.2f * prev_decision_rate %.2f (%.2f) [TRUE]\",\n      decision_rate_ewma, dr_margin, prev_decision_rate_ewma, dr_margin * prev_decision_rate_ewma);\n  } else {\n    kissat_extremely_verbose (solver,\n      \"hybrid restart: no condition met (fast glue %.2f < %.2f, decision rate %.2f >= %.2f)\",\n      fast_glue_ewma, glue_margin * slow_glue_ewma,\n      decision_rate_ewma, dr_margin * prev_decision_rate_ewma);\n  }\n\n  // Always update prev_decision_rate_ewma after check (works even if no restart)\n  solver->averages[mode].prev_decision_rate_ewma = decision_rate_ewma;\n\n  return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 554, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1332}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bd40c8190834b7f40dcc03765", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "a696d8b6672d3b252b38e20c0ed0d57f", "body": {"id": "resp_06dfe198bba47ce1006921ec4c61d481948f10b1e00c7ed896", "object": "response", "created_at": 1763830860, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_06dfe198bba47ce1006921ec4cbe688194828b5274d070dfb7", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  double *prev_decision_rate_ewma = &solver->prev_decision_rate_ewma;\n  bool triggered = false;\n\n  // First condition: Glue-based\n  if (fast_glue >= 0.98 * slow_glue) {\n    kissat_extremely_verbose (solver,\n      \"restarting: fast_glue %.2f >= 0.98 * slow_glue %.2f (%.2f)\",\n      fast_glue, slow_glue, 0.98 * slow_glue);\n    triggered = true;\n  } else if (decision_rate < 0.85 * (*prev_decision_rate_ewma)) {\n    kissat_extremely_verbose (solver,\n      \"restarting: decision_rate %.2f < 0.85 * prev_decision_rate_ewma %.2f (%.2f)\",\n      decision_rate, *prev_decision_rate_ewma, 0.85 * (*prev_decision_rate_ewma));\n    triggered = true;\n  }\n\n  // Update prev_decision_rate_ewma after check (even if not triggered)\n  *prev_decision_rate_ewma = decision_rate;\n\n  return triggered;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 357, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1135}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bcda881908400c53b05254240", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "c94b0485345c618079cb7f9e67d8d14b", "body": {"id": "resp_0525bfc66bdb1a28006921ec10ea4081968856b60b27b8ed6a", "object": "response", "created_at": 1763830800, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0525bfc66bdb1a28006921ec112d4c8196a88079a3bdfa09a3", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // Use reluctant restarts in stable phase\n  if (solver->stable)\n    return kissat_reluctant_triggered (&solver->reluctant);\n\n  // Gather averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve and update prev_decision_rate_ewma in solver struct\n  double prev_decision_rate_ewma = solver->prev_decision_rate_ewma;\n\n  // EWMA glue-drop check\n  bool glue_drop = (fast_glue >= 0.98 * slow_glue);\n\n  // Adaptive decision rate drop check\n  bool decision_rate_drop = (decision_rate < 0.85 * prev_decision_rate_ewma);\n\n  if (glue_drop || decision_rate_drop) {\n    if (decision_rate_drop && !glue_drop) {\n      kissat_extremely_verbose (\n        solver,\n        \"adaptive decision rate restart: \" \n        \"decision_rate_ewma %.6f < 0.85 * prev_decision_rate_ewma %.6f\",\n        decision_rate, prev_decision_rate_ewma);\n    } else if (glue_drop) {\n      kissat_extremely_verbose (\n        solver,\n        \"glue-drop restart: fast_glue_ewma %.6f >= 0.98 * slow_glue_ewma %.6f\",\n        fast_glue, slow_glue);\n    }\n    solver->prev_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  solver->prev_decision_rate_ewma = decision_rate;\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 428, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1206}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bd0f08190bfa15d273f3e4e9a", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "32440c32696e5942db2487e39515586a", "body": {"id": "resp_07d039cf2c6d1b85006921ec4dea708190a6f3b5dfe42277d1", "object": "response", "created_at": 1763830861, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_07d039cf2c6d1b85006921ec4e57f0819092b84cedb473b10e", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // Retrieve relevant averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Use solver->previous_decision_rate_ewma for previous value (must be initialized elsewhere)\n  double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Compute thresholds\n  const double glue_margin = 0.98 * slow_glue;\n  const double decision_margin = 0.85 * prev_decision_rate;\n\n  bool glue_trigger = (fast_glue >= glue_margin);\n  bool decision_rate_trigger = (decision_rate < decision_margin);\n\n  kissat_extremely_verbose (solver,\n    \"hybrid restart check: fast_glue=%.2f slow_glue=%.2f glue_margin=%.2f [%s], \"\n    \"decision_rate=%.4f prev_decision_rate=%.4f decision_margin=%.4f [%s]\",\n    fast_glue, slow_glue, glue_margin, glue_trigger ? \"TRIGGER\" : \"NO\",\n    decision_rate, prev_decision_rate, decision_margin, decision_rate_trigger ? \"TRIGGER\" : \"NO\"\n  );\n\n  bool res = false;\n  if (glue_trigger || decision_rate_trigger) {\n    res = true;\n  }\n\n  // Update prev_decision_rate_ewma only after check, regardless of trigger source\n  solver->previous_decision_rate_ewma = decision_rate;\n\n  return res;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 394, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1172}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bdf6881908e1c43468e0a4d6d", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "d0c5c01c88f0d991ce6f3b3ffdaa5ce7", "body": {"id": "resp_05872bd5d404b6c3006921ec5194048196b21e72481b9b850c", "object": "response", "created_at": 1763830865, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_05872bd5d404b6c3006921ec51d0088196a991df17b42df17c", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision_rate_ewma from solver field.\n  double prev_decision_rate = solver->prev_decision_rate_ewma;\n\n  // Hybrid EWMA Glue-Drop & Adaptive Decision Rate Restart:\n  // Restart if (fast >= 0.98 * slow) OR (decision_rate < 0.85 * prev_decision_rate)\n  bool glue_drop = (fast >= 0.98 * slow);\n  bool decision_drop = (decision_rate < 0.85 * prev_decision_rate);\n\n  // If either triggers, update prev_decision_rate_ewma and restart.\n  if (glue_drop || decision_drop) {\n    solver->prev_decision_rate_ewma = decision_rate;\n    kissat_extremely_verbose (\n      solver,\n      \"restarting: hybrid glue-drop/adaptive: \"\n      \"fast_glue %g slow_glue %g prev_decision_rate %g cur_decision_rate %g\",\n      fast, slow, prev_decision_rate, decision_rate\n    );\n    return true;\n  }\n\n  // Always update prev_decision_rate_ewma after each check (for next round)\n  solver->prev_decision_rate_ewma = decision_rate;\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 362, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1140}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec5bce648190b6bfa042f389ba4e", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "ca91f3539782005abe5cad7a149cc2de", "body": {"id": "resp_090f1c1a3a7b23cb006921ec10c2cc8190883c1143433895d9", "object": "response", "created_at": 1763830800, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_090f1c1a3a7b23cb006921ec1135d081909339a2dca3689f1d", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  if (solver->statistics.conflicts < solver->limits.restart.conflicts)\n    return false;\n\n  const int stable = solver->stable;\n  const double fast_glue = solver->averages[stable].fast_glue.value;\n  const double slow_glue = solver->averages[stable].slow_glue.value;\n  const double decision_rate = solver->averages[stable].decision_rate.value;\n\n  double *prev_decision_rate_ptr = &solver->prev_decision_rate_ewma;\n  double prev_decision_rate = *prev_decision_rate_ptr;\n\n  // Glue-based condition\n  const double glue_margin = 0.98;\n  bool glue_trigger = (fast_glue >= glue_margin * slow_glue);\n\n  // Decision-rate-based condition\n  const double dec_margin = 0.85;\n  bool dec_trigger = (decision_rate < dec_margin * prev_decision_rate);\n\n  bool triggered = false;\n\n  if (glue_trigger) {\n    kissat_extremely_verbose(\n      solver,\n      \"restarting: fast_glue %.3f >= %.2f * slow_glue %.3f (%.3f)\",\n      fast_glue, glue_margin, slow_glue, glue_margin * slow_glue);\n    triggered = true;\n  } else if (dec_trigger) {\n    kissat_extremely_verbose(\n      solver,\n      \"restarting: decision_rate %.3f < %.2f * prev_decision_rate %.3f (%.3f)\",\n      decision_rate, dec_margin, prev_decision_rate, dec_margin * prev_decision_rate);\n    triggered = true;\n  }\n\n  // Always update prev_decision_rate_ewma after each check\n  *prev_decision_rate_ptr = decision_rate;\n\n  return triggered;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 416, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1194}, "user": null, "metadata": {}}}, "error": null}
