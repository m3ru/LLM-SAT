{"id": "batch_req_6921ec61686c819089a74f77d3295185", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "bddbf0ce6f0f1d3be5ea72ed66c9519f", "body": {"id": "resp_0d3c6bdcf567ff17006921ec1eedec81948dc349c0805256c8", "object": "response", "created_at": 1763830814, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0d3c6bdcf567ff17006921ec1f3b108194b3f231dd7d8a3828", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n    assert (solver->unassigned);\n    if (!GET_OPTION (restart))\n        return false;\n    if (!solver->level)\n        return false;\n\n    // Conflict-based restart limit\n    if (CONFLICTS >= solver->limits.restart.conflicts)\n        return true;\n\n    // Skip other restarts in stable mode\n    if (solver->stable)\n        return false;\n\n    // Fetch glue and decision rate averages\n    const double fast_glue = AVERAGE (fast_glue);\n    const double slow_glue = AVERAGE (slow_glue);\n    const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n    double *prev_decision_rate = &solver->restart.reference_decision_rate;\n\n    // AGDRR: Check if glue and decision rate trigger applies\n    bool glue_condition = (fast_glue > slow_glue + 2.0);\n\n    // Avoid division by zero if prev_decision_rate is zero\n    bool decision_condition = false;\n    if (*prev_decision_rate > 0.0)\n        decision_condition = (decision_rate <= 0.95 * (*prev_decision_rate));\n\n    // If both triggers fire, prioritize conflicts (already handled above)\n    if (glue_condition && decision_condition)\n        return true;\n\n    return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 291, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1039}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec6162088190843b0ecf1a20da73", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "bb7a3a84b7928a7b974b317c85360bca", "body": {"id": "resp_0d2ee088aa221477006921ec223cb08196a87c2b1763fc5792", "object": "response", "created_at": 1763830818, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0d2ee088aa221477006921ec2277f48196965bbc44d711ab31", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict limit restart trigger (has highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable phase, do not do glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // AGDRR: Adaptive Glue-Decay Decision Rate Restart\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // We keep last restart's decision rate in solver->restart_decision_rate_ref\n  // It must be initialized at startup and updated in restarting logic after trigger.\n  double *refptr = &solver->restart_decision_rate_ref;\n  const double ref_decision_rate = *refptr;\n\n  // Main AGDRR condition: glue and decision rate drop\n  const bool glue_decay = (fast_glue > slow_glue + 2.0);\n\n  // Decision rate drop: less than 95% of the stored reference\n  bool decision_drop = false;\n  if (ref_decision_rate > 0.0) {\n    // 0.95 * reference\n    double threshold = 0.95 * ref_decision_rate;\n    if (decision_rate < threshold ||\n        kissat_double_equals(decision_rate, threshold)) // tie-break\n      decision_drop = true;\n  }\n\n  if (glue_decay && decision_drop) {\n    kissat_extremely_verbose(\n      solver,\n      \"AGDRR restart: fast_glue %.2f > slow_glue %.2f + 2.0 (%.2f), \"\n      \"decision_rate %.4f < 0.95 * reference %.4f (%.4f)\",\n      fast_glue, slow_glue, slow_glue + 2.0,\n      decision_rate, ref_decision_rate, 0.95 * ref_decision_rate);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 468, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1216}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec616858819080d9c54b7ded3c8f", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "26d50cae44ccc4806ec26bac663c3030", "body": {"id": "resp_0f6a709ecb92c9d7006921ec265c848190b50f604b77e367f3", "object": "response", "created_at": 1763830822, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0f6a709ecb92c9d7006921ec26a48c8190bdecedff61b24f50", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Primary trigger: conflict limit.\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable mode, no adaptive restart.\n  if (solver->stable)\n    return false;\n\n  // Compute fast/slow glue averages.\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n\n  // Compute decision rate moving average.\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // Retrieve stored reference decision rate.\n  double last_decision_rate = solver->restart.last_decision_rate;\n\n  // AGDRR: Check glue and decision rate thresholds.\n  bool glue_trigger = (fast > (slow + 2.0));\n  bool rate_trigger = false;\n\n  if (last_decision_rate > 0.0) {\n    double threshold = 0.95 * last_decision_rate;\n    rate_trigger = (decision_rate <= threshold);\n  }\n\n  // Both conditions must hold for adaptive restart.\n  if (glue_trigger && rate_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 286, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1034}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec616a548190b5e09cd202b621c0", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "39d9c2cf9c847efed9ce40d446e0fbb1", "body": {"id": "resp_0de4c2b6f2a7db98006921ec2985648196b6c75b882cbd7739", "object": "response", "created_at": 1763830825, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0de4c2b6f2a7db98006921ec29f3848196998a9c01c72938c5", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // 1. Conflict limit trigger (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // 2. If stable, do not trigger glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // 3. Adaptive Glue-Decay Decision Rate Restart (AGDRR)\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve reference decision rate at last restart\n  double last_restart_decision_rate = solver->restart_reference_decision_rate;\n\n  // Compute glue and decision rate trigger\n  bool glue_trigger = (fast > slow + 2.0);\n  bool decision_rate_trigger = (decision_rate <= 0.95 * last_restart_decision_rate);\n\n  if (glue_trigger && decision_rate_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 254, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1002}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec61699081908a621c2cc2f4a353", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "9c7239003991def8dc821593643aa724", "body": {"id": "resp_0486fb34c53ac480006921ec2cd6308190a9a2591e5f7015e0", "object": "response", "created_at": 1763830828, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0486fb34c53ac480006921ec2d3e94819080dcf6424ae2e17b", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable phase, skip adaptive glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // Get EWMA values for glue and decision rate\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Stored reference decision rate at last restart\n  double last_decision_rate = solver->restart.last_decision_rate;\n\n  // Decision rate threshold (5% drop)\n  double threshold = 0.95 * last_decision_rate;\n\n  // Glue-based and decision-rate-based restart condition\n  bool glue_condition = (fast_glue > slow_glue + 2.0);\n  bool decision_condition = (decision_rate <= threshold);\n\n  if (glue_condition && decision_condition) {\n    kissat_extremely_verbose (solver,\n      \"AGDRR restart: fast_glue %.2f > slow_glue %.2f + 2.0 and \"\n      \"decision_rate %.6f <= 0.95 * last_decision_rate %.6f (%.6f)\",\n      fast_glue, slow_glue, decision_rate, last_decision_rate, threshold);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 348, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1096}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec616f8c81909787bbe5e33619cc", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "055dd8aed6cefc8fbe2c45d61961ffb5", "body": {"id": "resp_0b9ceff60ec2954c006921ec3008308194990f0f2104994be8", "object": "response", "created_at": 1763830832, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0b9ceff60ec2954c006921ec30511481949ce62be60ae0d342", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart (priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable mode, skip glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // Fetch averages and last decision rate at restart\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n  const double last_decision_rate = solver->restart_last_decision_rate;\n\n  // Adaptive Glue-Decay + Decision Rate logic\n  const double glue_threshold = slow_glue + 2.0;\n  const double decision_rate_threshold = 0.95 * last_decision_rate;\n\n  bool glue_decay = (fast_glue > glue_threshold);\n  bool decision_drop = (decision_rate <= decision_rate_threshold);\n\n  // If both triggers fire, conflict-based takes priority (handled above)\n  if (glue_decay && decision_drop) {\n    kissat_extremely_verbose(\n      solver,\n      \"adaptive restart: fast_glue %.2f > slow_glue %.2f + 2.0, \"\n      \"decision_rate %.2f <= 0.95 * last_decision_rate %.2f\",\n      fast_glue, slow_glue, decision_rate, last_decision_rate);\n    return true;\n  }\n\n  // If glue decay only, no restart\n  // If decision drop only, no restart\n  // Only restart if both conditions are met\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 378, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1126}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec6164108190b2224efdf5ac6226", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "a761f3de84ab21ee4b78f2a5206af878", "body": {"id": "resp_0dee9febd43fa4e9006921ec344e248193b198ec7fb6598207", "object": "response", "created_at": 1763830836, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0dee9febd43fa4e9006921ec34dc2c81939a569f3422794293", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // First, conflict limit trigger (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // If in stable mode, do not check glue or decision rate triggers\n  if (solver->stable)\n    return false;\n\n  // Fetch averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Retrieve reference decision rate at last restart\n  double last_decision_rate = solver->restart.last_decision_rate_ewma;\n\n  // Compute difference for glue\n  const double glue_threshold = slow_glue + 2.0;\n  bool glue_trigger = (fast_glue > glue_threshold);\n\n  // Compute 5% drop threshold for decision rate\n  double decision_rate_threshold = 0.95 * last_decision_rate;\n  bool decision_rate_trigger = (decision_rate <= decision_rate_threshold);\n\n  // If both triggers fire, conflict limit already handled above.\n  if (glue_trigger && decision_rate_trigger)\n    return true;\n\n  if (glue_trigger && decision_rate_trigger)\n    return true;\n\n  // If exactly 5% drop, trigger as well (tie-breaker)\n  if (glue_trigger && (decision_rate == decision_rate_threshold))\n    return true;\n\n  // Otherwise, do not restart\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 350, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1098}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec6168648190b863682381564b88", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "22c8499b27242b7517a6983fefd9f804", "body": {"id": "resp_09b368985db822a2006921ec382138819480645112f049c1c7", "object": "response", "created_at": 1763830840, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_09b368985db822a2006921ec386be88194bf92432df6d98baf", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Always restart if over conflict limit (priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Do not restart on stable phase\n  if (solver->stable)\n    return false;\n\n  // Get glue averages\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n\n  // AGDRR: fast_glue_ewma > slow_glue_ewma + 2.0\n  if (fast > slow + 2.0) {\n    // Get decision rate EWMA and reference\n    const double curr_decision_rate = AVERAGE (decision_rate);\n    const double last_decision_rate = solver->restart_decision_rate;\n    // Check drop of at least 5% (0.95\u00d7 reference)\n    if (curr_decision_rate <= 0.95 * last_decision_rate) {\n      kissat_extremely_verbose (\n        solver,\n        \"AGDRR restart: fast_glue %.3f > slow_glue %.3f + 2.0 and decision_rate %.3f <= 0.95 * %.3f\",\n        fast, slow, curr_decision_rate, last_decision_rate);\n      return true;\n    }\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 324, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1072}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec6169ec8190970df66305b4cdaa", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "21e1376e16783938e8a944774f599c4f", "body": {"id": "resp_04f7607e1e5d6516006921ec5ae3d48195bf8329ec5d617296", "object": "response", "created_at": 1763830874, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_04f7607e1e5d6516006921ec5b1550819582f3451ceb23a628", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable mode, AGDRR does not trigger restarts except on conflict limit\n  if (solver->stable)\n    return false;\n\n  // AGDRR: Glue/decision-rate based restart\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve the last restart's decision rate reference\n  double last_restart_decision_rate = solver->restart_decision_rate_ref;\n  // If this is the first time, initialize reference with current value\n  if (last_restart_decision_rate == 0.0)\n    last_restart_decision_rate = solver->restart_decision_rate_ref = decision_rate;\n\n  // Glue comparison\n  const double glue_threshold = slow + 2.0;\n  // Decision rate drop threshold (at least 5% drop)\n  const double decision_rate_threshold = 0.95 * last_restart_decision_rate;\n\n  bool glue_trigger = (fast > glue_threshold);\n  bool decision_rate_trigger = (decision_rate <= decision_rate_threshold);\n\n  if (glue_trigger && decision_rate_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 328, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1076}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921ec61650c8190aa3d661477d4bdf2", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "5cbfae50cdf5e7f2a687481e99fbff10", "body": {"id": "resp_03bef114503cbfcf006921ec3cf500819490c935c8a63523d3", "object": "response", "created_at": 1763830844, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_03bef114503cbfcf006921ec3d5bd88194b5c44bde05e70bdf", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // 1. Conflict limit-based restart (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // 2. \"Stable\" phase disables glue/decision-based restarts\n  if (solver->stable)\n    return false;\n\n  // 3. Read glue and decision rate averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n  const double last_decision_rate = solver->restart_reference_decision_rate;\n\n  // 4. AGDRR heuristic check\n  const double glue_trigger = slow_glue + 2.0;\n  bool glue_condition = (fast_glue > glue_trigger);\n\n  // If no previous restart, or uninitialized value, skip decision rate check\n  bool decision_rate_condition = false;\n  if (last_decision_rate > 0) {\n    double threshold = 0.95 * last_decision_rate;\n    // Tie-breaking: trigger also on exactly 5% drop\n    decision_rate_condition = (decision_rate <= threshold);\n  }\n\n  if (glue_condition && decision_rate_condition)\n    return true;\n\n  return false;\n}\n</code>\n"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 322, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1070}, "user": null, "metadata": {}}}, "error": null}
