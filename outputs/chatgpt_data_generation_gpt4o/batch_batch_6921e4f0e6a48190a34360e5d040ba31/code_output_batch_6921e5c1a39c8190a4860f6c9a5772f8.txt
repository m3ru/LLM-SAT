{"id": "batch_req_6921e96617f88190917c4aff152d333f", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "4750014340fa857166d1478d524c370d", "body": {"id": "resp_00dfca31ce4b2c78006921e5cf5bd8819e8d8ba3768bbb575e", "object": "response", "created_at": 1763829199, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_00dfca31ce4b2c78006921e5cfd024819eb21e5450356957e3", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision rate EWMA (initialize to current if not set)\n  double *prev_decision_rate_ptr = &solver->prev_decision_rate_ewma;\n  if (isnan(*prev_decision_rate_ptr)) {\n    *prev_decision_rate_ptr = decision_rate;\n  }\n  const double prev_decision_rate = *prev_decision_rate_ptr;\n\n  bool glue_trigger = (fast_glue >= 0.98 * slow_glue);\n  bool decision_rate_trigger = (decision_rate < 0.85 * prev_decision_rate);\n\n  if (glue_trigger || decision_rate_trigger)\n  {\n    // Prioritize glue-triggered restart for logging if both are true\n    if (glue_trigger)\n    {\n      kissat_extremely_verbose (solver,\n        \"hybrid restart: fast glue %.2f >= 0.98 * slow glue %.2f (%.2f)\",\n        fast_glue, slow_glue, 0.98 * slow_glue);\n    }\n    else\n    {\n      kissat_extremely_verbose (solver,\n        \"hybrid restart: decision rate %.2f < 0.85 * prev decision rate %.2f (%.2f)\",\n        decision_rate, prev_decision_rate, 0.85 * prev_decision_rate);\n    }\n    // Update previous EWMA for next check\n    *prev_decision_rate_ptr = decision_rate;\n    return true;\n  }\n\n  // Always update the prev_decision_rate_ewma when not restarting\n  *prev_decision_rate_ptr = decision_rate;\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 442, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1220}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e96614b8819090af4484234b47a4", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "9566e78100e41baf2c61acb5909e1e62", "body": {"id": "resp_0e79097331d3fa8d006921e5cf903c81919d7fb4ca4de79ce4", "object": "response", "created_at": 1763829199, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0e79097331d3fa8d006921e5cfcb208191b313aecbb16d34d3", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // Get averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Use per-solver persistent storage for prev_decision_rate_ewma\n  double *prev_decision_rate_ptr = &solver->prev_decision_rate_ewma;\n  double prev_decision_rate = *prev_decision_rate_ptr;\n\n  // If this is first invocation, initialize prev_decision_rate_ewma\n  if (prev_decision_rate == 0.0)\n    prev_decision_rate = decision_rate;\n\n  bool glue_trigger = (fast_glue >= 0.98 * slow_glue);\n  bool rate_trigger = (decision_rate < 0.85 * prev_decision_rate);\n\n  bool triggered = false;\n  if (glue_trigger || rate_trigger) {\n    triggered = true;\n    // Only update prev_decision_rate_ewma on restart trigger\n    *prev_decision_rate_ptr = decision_rate;\n    if (glue_trigger)\n      kissat_extremely_verbose (solver,\n        \"hybrid-restart: triggered by glue (fast %.2f >= 0.98 * slow %.2f)\",\n        fast_glue, slow_glue);\n    else\n      kissat_extremely_verbose (solver,\n        \"hybrid-restart: triggered by decision rate (%.6f < 0.85 * %.6f)\",\n        decision_rate, prev_decision_rate);\n  }\n  else {\n    // If not triggered, keep the previous value\n    *prev_decision_rate_ptr = prev_decision_rate;\n  }\n\n  return triggered;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 425, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1203}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e96618708190b95e30285cce6b80", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "e622429f447ea738951072160e61573f", "body": {"id": "resp_02862a2e0d1e3df3006921e5d3f420819ea2f167aae4cea0fc", "object": "response", "created_at": 1763829203, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_02862a2e0d1e3df3006921e5d4349c819e91ce2b0ffd249134", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double fast_vs_slow = 0.98 * slow_glue;\n\n  kissat_extremely_verbose (solver,\n    \"hybrid restart: fast_glue %.2f vs slow_glue %.2f (thresh: %.2f)\",\n    fast_glue, slow_glue, fast_vs_slow);\n\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Use a static variable for previous decision rate (solver local)\n  // Place in solver->previous_decision_rate_ewma\n  // Initialize if zero (first use)\n  if (solver->previous_decision_rate_ewma == 0.0)\n    solver->previous_decision_rate_ewma = decision_rate;\n\n  bool glue_trigger = (fast_glue >= fast_vs_slow);\n  bool decision_trigger = (decision_rate < 0.85 * solver->previous_decision_rate_ewma);\n\n  kissat_extremely_verbose (solver,\n    \"hybrid restart: decision_rate %.6f vs previous %.6f (thresh: %.6f): trigger=%d\",\n    decision_rate, solver->previous_decision_rate_ewma, 0.85 * solver->previous_decision_rate_ewma, decision_trigger);\n\n  bool restart = glue_trigger || decision_trigger;\n\n  // Update previous_decision_rate_ewma after every check (regardless of restart)\n  solver->previous_decision_rate_ewma = decision_rate;\n\n  // If in stable mode, use reluctant restarts only\n  if (solver->stable)\n    return kissat_reluctant_triggered (&solver->reluctant);\n\n  return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 439, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1217}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e966127c8190adfe531a216c30ba", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "57f0ccc3f60310c540d212c27fdaf3c2", "body": {"id": "resp_0a2d670968789c4e006921e5d4139481a19e8b78d7928b4bf1", "object": "response", "created_at": 1763829204, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0a2d670968789c4e006921e5d4741081a198e44c0eb8e790f9", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // Hybrid EWMA Glue-Drop & Adaptive Decision Rate Restart\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Use a field in solver to store prev_decision_rate_ewma\n  // We use solver->prev_decision_rate_ewma (double), must be initialized elsewhere\n\n  bool restart = false;\n\n  // First criterion: Glue-based\n  if (fast_glue >= 0.98 * slow_glue)\n  {\n    restart = true;\n    kissat_extremely_verbose (solver,\n      \"restart: fast_glue %.6f >= 0.98 * slow_glue %.6f (%.6f)\",\n      fast_glue, slow_glue, 0.98 * slow_glue);\n  }\n  // Second criterion: Decision rate drop\n  else if (decision_rate < 0.85 * solver->prev_decision_rate_ewma)\n  {\n    restart = true;\n    kissat_extremely_verbose (solver,\n      \"restart: decision_rate %.6f < 0.85 * prev_decision_rate %.6f (%.6f)\",\n      decision_rate, solver->prev_decision_rate_ewma,\n      0.85 * solver->prev_decision_rate_ewma);\n  }\n\n  // Update prev_decision_rate_ewma after every check\n  solver->prev_decision_rate_ewma = decision_rate;\n\n  return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 395, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1173}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9661c5481909800f45068a502a3", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "ed50b1f877f6a52ddaef6494864b0dfd", "body": {"id": "resp_05e2c350fa75260f006921e5d41f1081918e92cd3fe3a91be2", "object": "response", "created_at": 1763829204, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_05e2c350fa75260f006921e5d463e0819197f842be3aa0beb5", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Store previous decision rate in solver->previous_decision_rate_ewma\n  double prev_decision_rate;\n  if (!solver->previous_decision_rate_initialized) {\n    prev_decision_rate = decision_rate;\n    solver->previous_decision_rate_ewma = decision_rate;\n    solver->previous_decision_rate_initialized = true;\n  } else {\n    prev_decision_rate = solver->previous_decision_rate_ewma;\n  }\n\n  bool restart = false;\n\n  // Glue-based trigger\n  const double glue_margin = 0.98 * slow_glue;\n  if (fast_glue >= glue_margin) {\n    kissat_extremely_verbose (solver,\n      \"restarting: fast_glue %.2f >= 0.98 * slow_glue %.2f = %.2f\",\n      fast_glue, slow_glue, glue_margin);\n    restart = true;\n  }\n  // Decision-rate-based trigger, only if glue trigger is not met (tie-break)\n  else if (decision_rate < 0.85 * prev_decision_rate) {\n    kissat_extremely_verbose (solver,\n      \"restarting: decision_rate %.2f < 0.85 * prev_decision_rate %.2f = %.2f\",\n      decision_rate, prev_decision_rate, 0.85 * prev_decision_rate);\n    restart = true;\n  }\n\n  // Always update previous_decision_rate_ewma after a check\n  solver->previous_decision_rate_ewma = decision_rate;\n\n  return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 430, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1208}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e96624548190bcaa70eadce966a0", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "56904670893890a0b64ba6c5dd295ab9", "body": {"id": "resp_0f94a8da17eff762006921e5d876988191be36a68794498c51", "object": "response", "created_at": 1763829208, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0f94a8da17eff762006921e5d8c52081918fbf7c5f57a43111", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // Hybrid EWMA Glue-Drop & Adaptive Decision Rate Restart\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision rate EWMA (persistently stored)\n  double prev_decision_rate_ewma = solver->adaptive.prev_decision_rate_ewma;\n\n  // Compute restart conditions\n  const bool glue_trigger = (fast_glue >= 0.98 * slow_glue);\n  const bool drate_trigger = (decision_rate < 0.85 * prev_decision_rate_ewma);\n\n  // Tie-break: prioritize glue-trigger if both are true\n  const bool restart = glue_trigger || drate_trigger;\n\n  // Update prev_decision_rate_ewma only if restart check is performed\n  solver->adaptive.prev_decision_rate_ewma = decision_rate;\n\n  if (restart) {\n    if (glue_trigger) {\n      kissat_extremely_verbose (\n        solver,\n        \"restarting: glue-trigger (fast_glue %.2f >= 0.98 * slow_glue %.2f)\",\n        fast_glue, slow_glue\n      );\n    } else if (drate_trigger) {\n      kissat_extremely_verbose (\n        solver,\n        \"restarting: decision-rate-trigger (decision_rate %.6f < 0.85 * prev_decision_rate_ewma %.6f)\",\n        decision_rate, prev_decision_rate_ewma\n      );\n    }\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 406, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1184}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e966ac0881908a3951a42d606101", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "4ad54b3f7b58f80f8d591dc716f652fc", "body": {"id": "resp_05ba9bdf2325bd45006921e95ffe80819d8dfdf8f5bd1490ad", "object": "response", "created_at": 1763830112, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_05ba9bdf2325bd45006921e9605010819d891fb48d67c8f88c", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  double *prev_decision_rate_ptr = &solver->restart.prev_decision_rate_ewma;\n  // lazy init for first run\n  if (*prev_decision_rate_ptr == 0.0)\n    *prev_decision_rate_ptr = decision_rate;\n\n  const double glue_trigger = 0.98 * slow_glue;\n  const double rate_trigger = 0.85 * (*prev_decision_rate_ptr);\n\n  bool do_restart = false;\n\n  if (fast_glue >= glue_trigger) {\n    do_restart = true;\n    // Tie-breaking: glue-drop has priority for logging\n    kissat_extremely_verbose (solver,\n      \"restarting: fast_glue %.2f >= 0.98 * slow_glue %.2f (%.2f)\",\n      fast_glue, slow_glue, glue_trigger);\n  } else if (decision_rate < rate_trigger) {\n    do_restart = true;\n    kissat_extremely_verbose (solver,\n      \"restarting: decision_rate %.2f < 0.85 * prev_decision_rate %.2f (%.2f)\",\n      decision_rate, *prev_decision_rate_ptr, rate_trigger);\n  }\n\n  // Update prev_decision_rate_ewma after every check\n  *prev_decision_rate_ptr = decision_rate;\n\n  return do_restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 385, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1163}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9661c9881909124b1a74dddb8bc", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "8750090034c3b6adb8cd4d5b8cac47b8", "body": {"id": "resp_067e2380ec829f5d006921e5d9093c819fa3114a8f25c3d73f", "object": "response", "created_at": 1763829209, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_067e2380ec829f5d006921e5d9953c819f824788523bfdb982", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (solver->statistics.conflicts < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = solver->averages[solver->stable].fast_glue.value;\n  const double slow_glue = solver->averages[solver->stable].slow_glue.value;\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  double *prev_decision_rate_ptr = &solver->restart.prev_decision_rate_ewma;\n  const double prev_decision_rate = *prev_decision_rate_ptr;\n\n  const bool glue_trigger = (fast_glue >= 0.98 * slow_glue);\n  const bool decision_trigger = (decision_rate < 0.85 * prev_decision_rate);\n\n  bool restart = false;\n  if (glue_trigger || decision_trigger) {\n    restart = true;\n    // Always update prev_decision_rate_ewma after the check\n    *prev_decision_rate_ptr = decision_rate;\n    // Tie-breaking: prioritize glue-trigger, but only one restart is triggered anyway\n  }\n\n  return restart;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 279, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1057}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9661508819083cea16eae212331", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "baf58a85115f8588945d0bf9a0830e3e", "body": {"id": "resp_08683b95dc9f6d4e006921e5db17f881a1bddb94e0fa8fc38d", "object": "response", "created_at": 1763829211, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_08683b95dc9f6d4e006921e5dd7ccc81a1af217874bb5f5cd8", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  double *prev_decision_rate_ptr = &solver->restart.prev_decision_rate_ewma;\n  // Initialize prev_decision_rate_ewma if it's the first check\n  if (*prev_decision_rate_ptr == 0.0)\n    *prev_decision_rate_ptr = decision_rate;\n\n  bool glue_trigger = (fast_glue >= 0.98 * slow_glue);\n  bool decision_rate_trigger = (decision_rate < 0.85 * (*prev_decision_rate_ptr));\n\n  if (glue_trigger || decision_rate_trigger) {\n    kissat_extremely_verbose (\n      solver,\n      \"hybrid glue-drop/adaptive decision rate restart: \"\n      \"fast_glue %.2f slow_glue %.2f prev_dec_rate %.6f dec_rate %.6f [%s]\",\n      fast_glue, slow_glue, *prev_decision_rate_ptr, decision_rate,\n      glue_trigger ? \"GLUE\" : (decision_rate_trigger ? \"DECISION_RATE\" : \"NONE\"));\n    *prev_decision_rate_ptr = decision_rate;\n    return true;\n  }\n\n  // Always update prev_decision_rate_ewma after each check\n  *prev_decision_rate_ptr = decision_rate;\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 367, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1145}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e96622648190b376bc5a553ab0c0", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "e388f4ff077ffd9e56e8d2763880cbdc", "body": {"id": "resp_023ce0e6eb8e1451006921e5db1eac8192970d5dbdeb479a5e", "object": "response", "created_at": 1763829211, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_023ce0e6eb8e1451006921e5db6794819282314264c6782933", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision rate EWMA (default if not initialized)\n  double prev_decision_rate_ewma = solver->prev_decision_rate_ewma;\n  bool trigger_glue = (fast >= 0.98 * slow);\n  bool trigger_decision_rate = (decision_rate < 0.85 * prev_decision_rate_ewma);\n\n  bool triggered = false;\n\n  if (trigger_glue) {\n    triggered = true;\n    kissat_extremely_verbose (solver,\n      \"restarting: fast glue %.6f >= 0.98 * slow glue %.6f [decision rate %.6f, prev %.6f]\",\n      fast, slow, decision_rate, prev_decision_rate_ewma);\n  } else if (trigger_decision_rate) {\n    triggered = true;\n    kissat_extremely_verbose (solver,\n      \"restarting: decision rate %.6f < 0.85 * prev decision rate %.6f [fast glue %.6f, slow glue %.6f]\",\n      decision_rate, prev_decision_rate_ewma, fast, slow);\n  }\n\n  // Update previous decision rate EWMA after every check\n  solver->prev_decision_rate_ewma = decision_rate;\n\n  return triggered;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 778, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 367, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1145}, "user": null, "metadata": {}}}, "error": null}
