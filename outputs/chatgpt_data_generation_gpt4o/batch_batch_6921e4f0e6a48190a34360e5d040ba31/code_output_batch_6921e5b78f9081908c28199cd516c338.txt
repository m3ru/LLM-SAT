{"id": "batch_req_6921e98e59cc8190bb9eb158dbfe185c", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "52aa5d9638683f4c581670d2b35d0a60", "body": {"id": "resp_0f77bca4e51d86b8006921e5f9973c819098dc41b419368a3d", "object": "response", "created_at": 1763829241, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0f77bca4e51d86b8006921e5fa050081908ac9c5e7f96b7a55", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Hard cap: always restart if enough conflicts.\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Get current averages.\n  const int mode = solver->stable;\n  const double fast_glue = solver->averages[mode].fast_glue.value;\n  const double slow_glue = solver->averages[mode].slow_glue.value;\n  const double decision_rate = solver->averages[mode].decision_rate.value;\n\n  // Static variable for adaptive EWMA of avg decision rate.\n  static double avg_decision_rate = 0.0;\n  if (avg_decision_rate == 0.0)\n    avg_decision_rate = decision_rate;\n  else\n    avg_decision_rate = 0.98 * avg_decision_rate + 0.02 * decision_rate;\n\n  // Thresholds: less sensitive in stable mode.\n  const double glue_ratio = solver->stable ? 1.30 : 1.15;\n  const double decision_ratio = solver->stable ? 0.70 : 0.85;\n\n  bool glue_trigger = (fast_glue > glue_ratio * slow_glue);\n  bool decision_trigger = (decision_rate < decision_ratio * avg_decision_rate);\n\n  if (glue_trigger && decision_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 327, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1115}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98eeedc81909b3690720756f097", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "3c844da92c313814910a66590b4bf841", "body": {"id": "resp_0622c5c99d060bd8006921e5be24988194be922d7448a3eeb7", "object": "response", "created_at": 1763829182, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0622c5c99d060bd8006921e5bf70708194b45c6ccf539ee5be", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Hard cap: conflict limit always triggers restart\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Extract averages for the current phase\n  const int phase = solver->stable;\n  const double fast_glue = solver->averages[phase].fast_glue.value;\n  const double slow_glue = solver->averages[phase].slow_glue.value;\n  const double decision_rate = solver->averages[phase].decision_rate.value;\n\n  // Maintain an EWMA for average decision rate\n  double *avg_decision_rate_ptr = &solver->averages[phase].average_decision_rate;\n  if (*avg_decision_rate_ptr == 0.0)\n    *avg_decision_rate_ptr = decision_rate;\n  else\n    *avg_decision_rate_ptr = 0.98 * (*avg_decision_rate_ptr) + 0.02 * decision_rate;\n\n  double glue_margin, rate_margin;\n  if (solver->stable) {\n    glue_margin = 1.30;\n    rate_margin = 0.70;\n  } else {\n    glue_margin = 1.15;\n    rate_margin = 0.85;\n  }\n\n  const double glue_limit = glue_margin * slow_glue;\n  const double rate_limit = rate_margin * (*avg_decision_rate_ptr);\n\n  kissat_extremely_verbose (solver,\n    \"restart: fast_glue %g, slow_glue %g, glue_limit %g, \"\n    \"decision_rate %g, avg_decision_rate %g, rate_limit %g\",\n    fast_glue, slow_glue, glue_limit,\n    decision_rate, *avg_decision_rate_ptr, rate_limit);\n\n  // Restart if glue and decision rate thresholds are crossed\n  if (fast_glue > glue_limit && decision_rate < rate_limit)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 442, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1230}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98e60e48190b85b4d41d9eb1491", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "765d56e5c3cb2e8d689646b66f348d01", "body": {"id": "resp_03de9fb9a0f8ac09006921e9864e188190aefbc51d426e0077", "object": "response", "created_at": 1763830150, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_03de9fb9a0f8ac09006921e98721a88190aea535b66e270cec", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Hard cap: Conflict limit trigger (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Gather averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n  double *average_decision_rate_ptr = &solver->averages[solver->stable].average_decision_rate;\n  double average_decision_rate = *average_decision_rate_ptr;\n\n  // Update average_decision_rate as an EWMA\n  // (initialize if zero)\n  if (average_decision_rate == 0.0)\n    average_decision_rate = decision_rate;\n  else\n    average_decision_rate = 0.98 * average_decision_rate + 0.02 * decision_rate;\n  *average_decision_rate_ptr = average_decision_rate;\n\n  // Thresholds: adjust if stable\n  double glue_threshold = solver->stable ? 1.30 : 1.15;\n  double rate_threshold = solver->stable ? 0.70 : 0.85;\n\n  bool glue_criterion = (fast_glue > glue_threshold * slow_glue);\n  bool rate_criterion = (decision_rate < rate_threshold * average_decision_rate);\n\n  if (glue_criterion && rate_criterion)\n  {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive hybrid restart: fast_glue %g > %.2f * slow_glue %g, \"\n      \"decision_rate %g < %.2f * avg_decision_rate %g\",\n      fast_glue, glue_threshold, slow_glue,\n      decision_rate, rate_threshold, average_decision_rate\n    );\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 438, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1226}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98e5bcc8190923a876dee6ebf6e", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "f7132e12f5c2a64f0b787d357f33eac0", "body": {"id": "resp_0ff4fe61a3b0c41c006921e5bdd74c8197858c80aea3fb2eff", "object": "response", "created_at": 1763829181, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0ff4fe61a3b0c41c006921e5be266c819797be07ded79f8504", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Initialize or retrieve persistent average_decision_rate\n  if (!solver->average_decision_rate_initialized) {\n    // On first call, initialize with the current decision_rate\n    solver->average_decision_rate = solver->averages[solver->stable].decision_rate.value;\n    solver->average_decision_rate_initialized = true;\n  }\n\n  const double fast_glue = solver->averages[solver->stable].fast_glue.value;\n  const double slow_glue = solver->averages[solver->stable].slow_glue.value;\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n  double *adr = &solver->average_decision_rate;\n\n  // Update EWMA for average decision rate\n  *adr = 0.98 * (*adr) + 0.02 * decision_rate;\n\n  // Set thresholds according to stable phase\n  double glue_threshold, decision_threshold;\n  if (solver->stable) {\n    glue_threshold = 1.30;\n    decision_threshold = 0.70;\n  } else {\n    glue_threshold = 1.15;\n    decision_threshold = 0.85;\n  }\n\n  // Hybrid condition: glue and decision rate\n  bool glue_trigger = (fast_glue > glue_threshold * slow_glue);\n  bool decision_trigger = (decision_rate < decision_threshold * (*adr));\n\n  // Extremely verbose output for debugging\n  kissat_extremely_verbose (\n    solver,\n    \"adaptive glue/decision restart: fast_glue=%.3f slow_glue=%.3f threshold=%.2f \"\n    \"decision_rate=%.3f average=%.3f threshold=%.2f glue_trigger=%d decision_trigger=%d\",\n    fast_glue, slow_glue, glue_threshold,\n    decision_rate, *adr, decision_threshold,\n    glue_trigger, decision_trigger\n  );\n\n  if (glue_trigger && decision_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 475, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1263}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98e633481908c7479c4eb125f84", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "dbd749b694ec02f132757bc4e1e90d4e", "body": {"id": "resp_078781b362ec0604006921e5bdd2808197b2984155c43a542b", "object": "response", "created_at": 1763829181, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_078781b362ec0604006921e5be2ae88197a73cca3ecda79613", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver)\n{\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Hard cap: conflict limit\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Retrieve averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // Persistent average decision rate: store in solver struct\n  double *average_decision_rate_ptr = &solver->restart_average_decision_rate;\n  // If first call, initialize to current decision_rate\n  if (*average_decision_rate_ptr == 0.0)\n    *average_decision_rate_ptr = decision_rate;\n\n  // EWMA update: avg = 0.98 * avg + 0.02 * current\n  *average_decision_rate_ptr = 0.98 * (*average_decision_rate_ptr) + 0.02 * decision_rate;\n  const double average_decision_rate = *average_decision_rate_ptr;\n\n  // Select thresholds\n  double glue_factor = 1.15;\n  double decision_factor = 0.85;\n  if (solver->stable) {\n    glue_factor = 1.30;\n    decision_factor = 0.70;\n  }\n\n  bool glue_trigger = (fast_glue > glue_factor * slow_glue);\n  bool decision_trigger = (decision_rate < decision_factor * average_decision_rate);\n\n  // If both glue and decision triggers are met, restart\n  if (glue_trigger && decision_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 381, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1169}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98efb24819086adf23d9619f281", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "0ccb2e7799d0662711cc871de51582e4", "body": {"id": "resp_0528e56c8b896845006921e5bdd1ac8194884753d9d4d35e5b", "object": "response", "created_at": 1763829181, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0528e56c8b896845006921e5be281c819484977e6ee2935024", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // Persistent average_decision_rate (EWMA) storage\n  static double average_decision_rate = 0.0;\n  static bool initialized = false;\n  if (!initialized) {\n    average_decision_rate = decision_rate;\n    initialized = true;\n  } else {\n    average_decision_rate = 0.98 * average_decision_rate + 0.02 * decision_rate;\n  }\n\n  // Thresholds\n  double glue_thresh = 1.15;\n  double decision_thresh = 0.85;\n  if (solver->stable) {\n    glue_thresh = 1.30;\n    decision_thresh = 0.70;\n  }\n\n  bool glue_condition = (fast_glue > glue_thresh * slow_glue);\n  bool decision_condition = (decision_rate < decision_thresh * average_decision_rate);\n\n  // If both glue and decision conditions are equally met, conflict limit takes priority (handled above)\n  if (glue_condition && decision_condition)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 330, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1118}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98e5fe48190921df57558a31c49", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "b0c7368e68399aac43c7e91f63748c89", "body": {"id": "resp_05776e345ee850dd006921e5bda21c8196a2e5c9de709e86f7", "object": "response", "created_at": 1763829181, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_05776e345ee850dd006921e5be24508196a70aa4766add0ca5", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Hard conflict limit trigger (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Retrieve averages for current mode (stable or focused)\n  const int mode = solver->stable;\n  const double fast_glue = solver->averages[mode].fast_glue.value;\n  const double slow_glue = solver->averages[mode].slow_glue.value;\n  const double decision_rate = solver->averages[mode].decision_rate.value;\n\n  // EWMA of average decision rate, stored per mode\n  double *average_decision_rate = &solver->averages[mode].average_decision_rate;\n\n  // Initialize average_decision_rate if first time\n  if (*average_decision_rate == 0)\n    *average_decision_rate = decision_rate;\n  else\n    *average_decision_rate = 0.98 * (*average_decision_rate) + 0.02 * decision_rate;\n\n  // Thresholds: relaxed when stable\n  double glue_margin = solver->stable ? 1.30 : 1.15;\n  double decision_margin = solver->stable ? 0.70 : 0.85;\n\n  bool glue_condition = (fast_glue > glue_margin * slow_glue);\n  bool decision_condition = (decision_rate < decision_margin * (*average_decision_rate));\n\n  if (glue_condition && decision_condition)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 351, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1139}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98e5af08190994a5ae34313f643", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "70f69fd7c5f83f14ab6f970672bbc3aa", "body": {"id": "resp_0a1cb7f499c740e8006921e5be13188197901b023c9d876466", "object": "response", "created_at": 1763829182, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0a1cb7f499c740e8006921e5bea7b881978f3a829ce8fb8e08", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict limit hard cap\n  if (solver->statistics.conflicts >= solver->limits.restart.conflicts)\n    return true;\n\n  const int stable = solver->stable;\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Maintain an EWMA of decision rate as \"average_decision_rate\"\n  double *avg_decision_rate_ptr = &solver->average_decision_rate;\n  if (!isfinite(*avg_decision_rate_ptr) || *avg_decision_rate_ptr == 0.0)\n    *avg_decision_rate_ptr = decision_rate;\n  else\n    *avg_decision_rate_ptr = 0.98 * (*avg_decision_rate_ptr) + 0.02 * decision_rate;\n\n  const double average_decision_rate = *avg_decision_rate_ptr;\n\n  // Sensitivity thresholds\n  double glue_threshold = stable ? 1.30 : 1.15;\n  double decision_threshold = stable ? 0.70 : 0.85;\n\n  bool glue_trigger = (fast > glue_threshold * slow);\n  bool decision_trigger = (decision_rate < decision_threshold * average_decision_rate);\n\n  kissat_extremely_verbose (solver,\n    \"restart glue %g %s %g * %g (slow glue) [stable=%d]\",\n    fast, (glue_trigger ? \">\" : \"<=\"), glue_threshold, slow, stable);\n\n  kissat_extremely_verbose (solver,\n    \"restart decision rate %g %s %g * %g (avg_dec_rate) [stable=%d]\",\n    decision_rate, (decision_trigger ? \"<\" : \">=\"),\n    decision_threshold, average_decision_rate, stable);\n\n  // Only trigger if BOTH the glue and decision criteria are met\n  if (glue_trigger && decision_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 454, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1242}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98e5ef88190958bedcdf66a027b", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "ac0d5cac73f6269b9f1033faf5597b27", "body": {"id": "resp_0c69f4fcb1d494e1006921e5c3401481959402b1a44123acbb", "object": "response", "created_at": 1763829187, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0c69f4fcb1d494e1006921e5c378788195b996cefd0a535883", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver)\n{\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Hard cap: conflict limit enforcement\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Fetch relevant averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Static: keep an EWMA of average_decision_rate across calls\n  static double average_decision_rate = 0.0;\n  if (average_decision_rate <= 0.0)\n    average_decision_rate = decision_rate;\n  else\n    average_decision_rate = 0.98 * average_decision_rate + 0.02 * decision_rate;\n\n  // Thresholds for glue and decision rate\n  double glue_ratio = solver->stable ? 1.30 : 1.15;\n  double decision_ratio = solver->stable ? 0.70 : 0.85;\n\n  bool glue_condition = (fast_glue > glue_ratio * slow_glue);\n  bool decision_condition = (decision_rate < decision_ratio * average_decision_rate);\n\n  kissat_extremely_verbose(\n    solver,\n    \"restart glue/decision thresholds: fast_glue %.4f, slow_glue %.4f, threshold %.2f; \"\n    \"decision_rate %.4f, avg_decision_rate %.4f, threshold %.2f (stable=%d)\",\n    fast_glue, slow_glue, glue_ratio,\n    decision_rate, average_decision_rate, decision_ratio,\n    solver->stable);\n\n  if (glue_condition && decision_condition)\n    return true;\n\n  return false;\n}\n</code>\n"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 396, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1184}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e98e57948190af3173020ea18aba", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "10669cc273ae8cf7251d4a9bd3978422", "body": {"id": "resp_0aac3bc76544c2b9006921e5c397288194988faa80ed0ff964", "object": "response", "created_at": 1763829187, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0aac3bc76544c2b9006921e5c3d28081949ad3e9c88c9a9543", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Hard conflict cap: always take priority\n  if (solver->statistics.conflicts >= solver->limits.restart.conflicts)\n    return true;\n\n  // Read glue and decision rates from the current stage\n  const int stable = solver->stable;\n  const double fast_glue = solver->averages[stable].fast_glue.value;\n  const double slow_glue = solver->averages[stable].slow_glue.value;\n  const double decision_rate = solver->averages[stable].decision_rate.value;\n\n  // Use a persistent average decision rate (EWMA)\n  double *avg_decision_rate_ptr = &solver->average_decision_rate;\n  double avg_decision_rate = *avg_decision_rate_ptr;\n  avg_decision_rate = 0.98 * avg_decision_rate + 0.02 * decision_rate;\n  *avg_decision_rate_ptr = avg_decision_rate;\n\n  // Set thresholds\n  double glue_threshold = stable ? 1.30 : 1.15;\n  double decision_threshold = stable ? 0.70 : 0.85;\n\n  bool glue_criterion = (fast_glue > glue_threshold * slow_glue);\n  bool decision_criterion = (decision_rate < decision_threshold * avg_decision_rate);\n\n  kissat_extremely_verbose (solver,\n    \"restart thresholds: glue %g (%.2f * %g), decision rate %g (%.2f * %g)\",\n    glue_threshold * slow_glue, glue_threshold, slow_glue,\n    decision_threshold * avg_decision_rate, decision_threshold, avg_decision_rate);\n\n  if (glue_criterion && decision_criterion)\n    return true;\n  return false;\n}\n</code>\n"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 788, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 401, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1189}, "user": null, "metadata": {}}}, "error": null}
