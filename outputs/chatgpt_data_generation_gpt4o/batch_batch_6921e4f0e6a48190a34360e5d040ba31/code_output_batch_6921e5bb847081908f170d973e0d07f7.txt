{"id": "batch_req_6921e9a0e94481909b099ff823a2a8de", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "193104c88656c00393eb78bf3c052542", "body": {"id": "resp_09da840000be7405006921e5fb5a488195b731116d42bba011", "object": "response", "created_at": 1763829243, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_09da840000be7405006921e5fb9cbc8195afb9bab2ecebab14", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Always trigger restart if conflict limit reached\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only allow glue/decision-rate based restart in unstable mode\n  if (solver->stable)\n    return false;\n\n  // Get moving averages\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Previous decision rate is kept in reluctant.prev_decision_rate\n  // (Assumed available as an extra field in the reluctant struct)\n  const double prev_decision_rate = solver->reluctant.prev_decision_rate;\n\n  // Dual-threshold check\n  const bool glue_triggered = (fast_glue > 0.85 * slow_glue);\n  const bool decisionrate_triggered = (decision_rate < 0.95 * prev_decision_rate);\n\n  if (glue_triggered && decisionrate_triggered) {\n    kissat_extremely_verbose (\n      solver,\n      \"restart triggered by dual-threshold: fast_glue=%.2f > 0.85*slow_glue=%.2f, decision_rate=%.2f < 0.95*prev=%.2f\",\n      fast_glue, 0.85 * slow_glue, decision_rate, 0.95 * prev_decision_rate);\n\n    // update previous_decision_rate for next window\n    solver->reluctant.prev_decision_rate = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 384, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1152}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0f4e48190bd4ffd239cbed647", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "391595f57df7bc649c41c52e090611d5", "body": {"id": "resp_0bf30677fdc51df6006921e5fe9ec4819591e8276139154907", "object": "response", "created_at": 1763829246, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0bf30677fdc51df6006921e5ff0b808195ac68bbde01fc378e", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict limit trigger (priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only apply glue/decision-rate trigger in unstable mode\n  if (solver->stable)\n    return false;\n\n  // Gather EWMA values\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n  const double prev_decision_rate = solver->averages[solver->stable].decision_rate.prev_value;\n\n  // Dual-threshold adaptive trigger\n  const bool glue_trigger = (fast_glue > 0.85 * slow_glue);\n  const bool dr_trigger = (decision_rate < 0.95 * prev_decision_rate);\n\n  kissat_extremely_verbose (solver,\n    \"dual-threshold restart: fast_glue=%g, slow_glue=%g, decision_rate=%g, prev_decision_rate=%g\",\n    fast_glue, slow_glue, decision_rate, prev_decision_rate);\n\n  if (glue_trigger && dr_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 302, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1070}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a13bc08190bba1cf6c6f03e03b", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "243285f1bb4a95b8321e90fdaca860c2", "body": {"id": "resp_0f1594a59e1d43e1006921e601f6108195b39da84c9fdab2d5", "object": "response", "created_at": 1763829249, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0f1594a59e1d43e1006921e602341c81958707242aa3fcf89d", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // First, check the hard conflict limit.\n  if (solver->statistics.conflicts >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only consider the dual-threshold glue-decision adaptive trigger in unstable mode.\n  if (solver->stable)\n    return false;\n\n  // Gather averages.\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve the previous decision rate EWMA.\n  const double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Compute thresholds.\n  const double glue_threshold = 0.85 * slow_glue;\n  const double decision_rate_threshold = 0.95 * prev_decision_rate;\n\n  bool glue_condition = (fast_glue > glue_threshold);\n  bool decision_rate_condition = (decision_rate < decision_rate_threshold);\n\n  if (glue_condition && decision_rate_condition)\n  {\n    // After restart, update the previous_decision_rate_ewma.\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 301, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1069}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0f5a081908c59e45042450bed", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "f808991f3ad0eb87ca1ea0635d9a5ccb", "body": {"id": "resp_0f34092629c9aa8c006921e60563e48195897caff36005ee93", "object": "response", "created_at": 1763829253, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0f34092629c9aa8c006921e6092bac81959441bb6a831d8955", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Priority: always restart if conflict limit reached\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only apply glue/decision-rate restart in unstable mode\n  if (solver->stable)\n    return false;\n\n  // Get current EWMA values\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision rate EWMA\n  double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Adaptive dual-threshold condition\n  bool glue_trigger = (fast_glue > 0.85 * slow_glue);\n  bool decision_rate_trigger = (decision_rate < 0.95 * prev_decision_rate);\n\n  if (glue_trigger && decision_rate_trigger) {\n    kissat_extremely_verbose (solver,\n      \"restart dual-threshold: fast_glue %.3f > 0.85*slow_glue %.3f and \"\n      \"decision_rate %.3f < 0.95*prev_decision_rate %.3f\",\n      fast_glue, 0.85 * slow_glue, decision_rate, 0.95 * prev_decision_rate);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 334, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1102}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0f1e081908e7aab2980b0f9ac", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "ea57a4e5629209289e39a2c4a8d97480", "body": {"id": "resp_0e3ab8e0c43545c2006921e60bcc24819694eaf3d3af644664", "object": "response", "created_at": 1763829259, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0e3ab8e0c43545c2006921e60bfeb081969c0e8fa3dc0e8beb", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only consider glue/decision-based restart in unstable mode\n  if (solver->stable)\n    return false;\n\n  // EWMA/thresholds\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // 'previous_decision_rate_ewma' is maintained in solver->previous_decision_rate_ewma\n  // (initialize to decision_rate at startup in the initialization code)\n\n  const double glue_threshold = 0.85 * slow_glue;\n  const double decision_rate_threshold = 0.95 * solver->previous_decision_rate_ewma;\n\n  bool glue_trigger = (fast_glue > glue_threshold);\n  bool decision_trigger = (decision_rate < decision_rate_threshold);\n\n  kissat_extremely_verbose (solver,\n    \"dual-threshold: fast_glue %.2f > %.2f (0.85*slow_glue %.2f)? %s, \"\n    \"decision_rate %.2f < %.2f (0.95*prev_decision_rate %.2f)? %s\",\n    fast_glue, glue_threshold, slow_glue, glue_trigger ? \"yes\" : \"no\",\n    decision_rate, decision_rate_threshold, solver->previous_decision_rate_ewma, decision_trigger ? \"yes\" : \"no\");\n\n  if (glue_trigger && decision_trigger) {\n    // After restart, update previous_decision_rate_ewma\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>\n"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 421, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1189}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0eff08190b3b0819f45aef769", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "38faf7cece9fe7d6c506530bc5dfd78f", "body": {"id": "resp_05187007363d30e2006921e60f2af08194aeb25ff121432e74", "object": "response", "created_at": 1763829263, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_05187007363d30e2006921e60f78a48194a82e0cfd11c6a3e8", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver)\n{\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // First, check the conflict limit trigger (has highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only perform this heuristic in unstable mode.\n  if (solver->stable)\n    return kissat_reluctant_triggered (&solver->reluctant);\n\n  // EWMA values for glue and decision rate\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision rate EWMA (stored in solver->previous_decision_rate_ewma)\n  const double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Dual-threshold logic:\n  // (fast_glue > 0.85 * slow_glue) AND (decision_rate < 0.95 * prev_decision_rate)\n  bool glue_condition = (fast_glue > 0.85 * slow_glue);\n  bool decision_rate_condition = (decision_rate < 0.95 * prev_decision_rate);\n\n  if (glue_condition && decision_rate_condition)\n  {\n    // After restart, update previous_decision_rate_ewma\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 337, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1105}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0ebcc8190ab86542673427c30", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "b11cf16872bb79cb90658bbfdf8d21c7", "body": {"id": "resp_0336ec9ea54baf98006921e6124bbc81948cecdb4a9842d4f1", "object": "response", "created_at": 1763829266, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0336ec9ea54baf98006921e612939c8194bd8669a1663a362d", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only apply dual-threshold heuristic in unstable mode\n  if (!solver->stable) {\n    const double fast_glue = AVERAGE (fast_glue);\n    const double slow_glue = AVERAGE (slow_glue);\n    const double decision_rate = AVERAGE (decision_rate);\n\n    // 'previous_decision_rate' is a shadow variable kept in solver->previous_decision_rate\n    // It is updated externally after a restart.\n    const double previous_decision_rate = solver->previous_decision_rate;\n\n    const double glue_threshold = 0.85 * slow_glue;\n    const double decision_rate_threshold = 0.95 * previous_decision_rate;\n\n    // If previous_decision_rate is not initialized, do not trigger restart on this heuristic\n    if (previous_decision_rate > 0.0) {\n      if (fast_glue > glue_threshold && decision_rate < decision_rate_threshold)\n        return true;\n    }\n  }\n\n  // In stable mode, use reluctant-based restart as fallback\n  if (solver->stable)\n    return kissat_reluctant_triggered (&solver->reluctant);\n\n  return false;\n}\n</code>\n"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 317, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1085}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0f95c8190a1ecf69063eb3b75", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "68f23da2c1ac85ab19bb9496ee181a4d", "body": {"id": "resp_0ad784a8cf3504d2006921e99c240481948259201d50100665", "object": "response", "created_at": 1763830172, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0ad784a8cf3504d2006921e99d315c81948f0438a459db35d4", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only use glue/decision-rate based restart in non-stable mode\n  if (solver->stable)\n    return false;\n\n  // Glue-based and decision-rate-based adaptive restart\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double threshold_glue = 0.85 * slow_glue;\n\n  const double curr_decision_rate = AVERAGE (decision_rate);\n  double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  // If previous_decision_rate_ewma is not initialized, do not restart\n  if (prev_decision_rate == 0.0)\n    return false;\n\n  const double threshold_decision_rate = 0.95 * prev_decision_rate;\n\n  bool glue_trigger = (fast_glue > threshold_glue);\n  bool decision_rate_trigger = (curr_decision_rate < threshold_decision_rate);\n\n  if (glue_trigger && decision_rate_trigger) {\n    // After restart, update previous_decision_rate_ewma\n    solver->previous_decision_rate_ewma = curr_decision_rate;\n    kissat_extremely_verbose(solver,\n      \"adaptive restart: fast_glue %.2f > %.2f (0.85*slow_glue), \"\n      \"decision_rate %.2f < %.2f (0.95*prev_decision_rate)\",\n      fast_glue, threshold_glue,\n      curr_decision_rate, threshold_decision_rate);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 405, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1173}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0eb948190b996eba764660ad6", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "2a4f732ad3881edde702185f825d976d", "body": {"id": "resp_04de431e50ddbb19006921e616e2248195b033dc5bdc5f3691", "object": "response", "created_at": 1763829270, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_04de431e50ddbb19006921e61731c481959f93effd9dd1e53a", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict limit trigger (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only apply dual-threshold mechanism in unstable mode\n  if (solver->stable)\n    return kissat_reluctant_triggered (&solver->reluctant);\n\n  // Dual-threshold glue-decision adaptive trigger\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double glue_threshold = 0.85 * slow_glue;\n\n  const double decision_rate = AVERAGE (decision_rate);\n  const double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  bool glue_condition = (fast_glue > glue_threshold);\n  bool decision_condition = (decision_rate < 0.95 * prev_decision_rate);\n\n  if (glue_condition && decision_condition)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 250, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1018}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e9a0f19c8190af6fa78da1cb2eb6", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "79106a34aa7fd6c15ca0a4a28ca08bf1", "body": {"id": "resp_0c0b02ff04de045b006921e61ad920819785585f266e6e2e17", "object": "response", "created_at": 1763829274, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0c0b02ff04de045b006921e61b0fb08197a11100a7ef05c0d4", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // 1. Conflict limit restart check (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // Only perform adaptive glue/decision-rate restart in unstable mode\n  if (solver->stable)\n    return kissat_reluctant_triggered (&solver->reluctant);\n\n  // 2. Dual-threshold glue/decision restart\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision rate from solver struct\n  double previous_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Adaptive restart trigger check\n  bool glue_condition = (fast_glue > 0.85 * slow_glue);\n  bool decision_rate_condition = (decision_rate < 0.95 * previous_decision_rate);\n\n  if (glue_condition && decision_rate_condition) {\n    // Update previous decision rate for next round\n    solver->previous_decision_rate_ewma = decision_rate;\n    return true;\n  }\n\n  // Always update previous_decision_rate_ewma if not restarting\n  solver->previous_decision_rate_ewma = decision_rate;\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 768, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 323, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1091}, "user": null, "metadata": {}}}, "error": null}
