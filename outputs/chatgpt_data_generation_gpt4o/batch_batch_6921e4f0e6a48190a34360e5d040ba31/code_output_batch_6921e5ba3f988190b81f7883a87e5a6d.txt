{"id": "batch_req_6921e62235dc8190a8c5e4df9132b576", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "6bb6c2e6120d612c5316f70fd6fb8636", "body": {"id": "resp_0d8a1cc84bb84dd0006921e61aee0481949620e01c5eb102cf", "object": "response", "created_at": 1763829274, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0d8a1cc84bb84dd0006921e61b48788194b7a88b0c291bd7e7", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart trigger (priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable phase, do not use glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // Compute glue averages and decision rate\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Reference value for decision rate at last restart\n  double last_restart_decision_rate = solver->restart_decision_rate;\n\n  // Glue difference check\n  if (fast_glue > slow_glue + 2.0) {\n    // Decision rate drop check\n    const double threshold = 0.95 * last_restart_decision_rate;\n    if (decision_rate <= threshold) {\n      // Update reference for next restart\n      solver->restart_decision_rate = decision_rate;\n      return true;\n    }\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 267, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1015}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e62259ec819089e29d57b631b120", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "325ea91d98daf8403a579a0d47ab30bf", "body": {"id": "resp_04312520bbf9d27a006921e5c11b5c81949f14d4fc32a8abb7", "object": "response", "created_at": 1763829185, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_04312520bbf9d27a006921e5c1b3c481949ef716184975666c", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Conflict limit restart (always prioritized)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // If in stable phase, do not restart on glue/decision triggers\n  if (solver->stable)\n    return false;\n\n  // AGDRR: Check glue and decision rate criteria\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Retrieve the reference decision rate saved at the last restart\n  const double last_restart_decision_rate = solver->restart_reference_decision_rate;\n\n  // Compute thresholds\n  const double glue_threshold = slow_glue + 2.0;\n  const double decision_rate_threshold = 0.95 * last_restart_decision_rate;\n\n  // For tie-breaking: exact 5% drop also triggers\n  bool glue_condition = (fast_glue > glue_threshold);\n  bool decision_rate_condition = (decision_rate < decision_rate_threshold) ||\n                                 (decision_rate == decision_rate_threshold);\n\n  if (glue_condition && decision_rate_condition)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 298, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1046}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e62245d88190a0dbcab48da61ea8", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "be9ad055a9577a9c0e620fc7c6ca82be", "body": {"id": "resp_0e61337dcf9f407f006921e5c0f3ec8196a717eafa2b7747a0", "object": "response", "created_at": 1763829184, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0e61337dcf9f407f006921e5c14b148196a59f842268b6c4d6", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict limit trigger (always highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable mode, skip glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // AGDRR: Glue and decision rate trigger\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double glue_threshold = slow_glue + 2.0;\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Use the last recorded decision rate (per AGDRR spec)\n  double ref_decision_rate = solver->restart_decision_rate_ref;\n\n  // If no reference yet (first time), do not trigger by decision rate\n  bool have_ref = (ref_decision_rate > 0.0);\n\n  bool glue_trigger = (fast_glue > glue_threshold);\n  bool decision_trigger = false;\n\n  if (have_ref) {\n    // Drop by at least 5% (0.95x reference) triggers; exactly 5% also triggers\n    decision_trigger = (decision_rate <= 0.95 * ref_decision_rate);\n  }\n\n  kissat_extremely_verbose(\n    solver,\n    \"AGDRR: fast_glue %.2f slow_glue %.2f (threshold %.2f) glue_trigger %d decision_rate %.4f ref %.4f trigger %d\",\n    fast_glue, slow_glue, glue_threshold, glue_trigger, decision_rate, ref_decision_rate, decision_trigger);\n\n  if (glue_trigger && decision_trigger) {\n    // After restart, save ref for next window\n    solver->restart_decision_rate_ref = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 427, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1175}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e62241bc8190959a4c0cac033102", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "66111e71f64d41ecde9cc2d3d2e01eca", "body": {"id": "resp_068803d1a8cb9d48006921e5c707ac8196a9e15f58eab8810b", "object": "response", "created_at": 1763829191, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_068803d1a8cb9d48006921e5c79b3c8196ad9411038f24d550", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart trigger (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable mode, skip glue and decision-rate based restarts\n  if (solver->stable)\n    return false;\n\n  // Fetch moving averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Retrieve the reference decision rate at last restart\n  const double last_decision_rate = solver->restarting.decision_rate_at_last_restart;\n\n  // Glue-based and decision-rate-based restart trigger\n  bool glue_trigger = (fast_glue > slow_glue + 2.0);\n\n  // Decision rate drop: check for drop >= 5%\n  bool decision_rate_trigger = false;\n  if (last_decision_rate > 0.0) {\n    double threshold = 0.95 * last_decision_rate;\n    if (decision_rate <= threshold)\n      decision_rate_trigger = true;\n  }\n\n  // Both triggers must fire for glue/decision-based restart\n  if (glue_trigger && decision_rate_trigger) {\n    kissat_extremely_verbose(solver,\n      \"AGDRR restart: fast_glue %.2f > slow_glue %.2f + 2.0 and decision_rate %.4f <= 0.95 * %.4f\",\n      fast_glue, slow_glue, decision_rate, last_decision_rate);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 381, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1129}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e622451c8190a3ef1144f69395fb", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "8632f5877290c247e84b1d03abcfc58a", "body": {"id": "resp_0ebb1a0bac44ee89006921e5c6d6b08194bf6a4fb88dde1d5a", "object": "response", "created_at": 1763829190, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0ebb1a0bac44ee89006921e5c756608194b1829173bb4b284e", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // 1. Conflict limit: always a hard trigger\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    return true;\n  }\n\n  // 2. In stable mode, skip glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // 3. Compute AGDRR triggers\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n  const double last_decision_rate = solver->last_restart_decision_rate;\n\n  // (a) fast_glue > slow_glue + 2.0\n  bool glue_trigger = (fast_glue > slow_glue + 2.0);\n\n  // (b) decision_rate < 0.95 * last_decision_rate\n  bool decision_rate_trigger = false;\n  if (last_decision_rate > 0.0) {\n    double threshold = 0.95 * last_decision_rate;\n    // Exact 5% drop triggers\n    if (kissat_iszero (decision_rate - threshold))\n      decision_rate_trigger = true;\n    else if (decision_rate < threshold)\n      decision_rate_trigger = true;\n  }\n\n  // (c) Only if both triggers\n  if (glue_trigger && decision_rate_trigger) {\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 357, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1105}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e622426c81908b525886e50c1c44", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "88fd19cdd10cc00e862d0c137b0ef0ca", "body": {"id": "resp_0049ffc1666eb235006921e5ccf97c8194ba4f5516dc089f7c", "object": "response", "created_at": 1763829197, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0049ffc1666eb235006921e5cd91ec8194a4a00449a161de57", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Check conflict limit trigger (priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable mode, do not consider glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // Gather averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Retrieve last restart decision rate reference\n  const double last_restart_decision_rate = solver->restart_decision_rate;\n\n  // Glue threshold for restart (margin = +2.0)\n  const double glue_threshold = slow_glue + 2.0;\n\n  // Check glue and decision rate triggers\n  bool glue_trigger = (fast_glue > glue_threshold);\n  bool decision_rate_trigger = (decision_rate <= 0.95 * last_restart_decision_rate);\n\n  // If glue and decision rate condition met, restart\n  if (glue_trigger && decision_rate_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 278, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1026}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e6224cbc819084f0e818ee6716e5", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "05ae60134f4f6f7fabb6ef84a25d1e4d", "body": {"id": "resp_03d8ecd2e4bff35e006921e5cef0c48193bc3867bb6cb170df", "object": "response", "created_at": 1763829198, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_03d8ecd2e4bff35e006921e5cf3dd4819387a5a06b4d64b42e", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver)\n{\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Conflict-based restart\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable mode, skip glue/decision checks\n  if (solver->stable)\n    return false;\n\n  // Get current averages\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n\n  // Retrieve and update the reference decision rate (since last restart)\n  double *ref_decision_rate = &solver->restart_decision_rate_ref;\n  // If not initialized, set at first call\n  if (isnan(*ref_decision_rate))\n    *ref_decision_rate = decision_rate;\n\n  // Glue and decision rate based restart\n  bool glue_trigger = (fast_glue > slow_glue + 2.0);\n\n  bool rate_trigger = false;\n  if (*ref_decision_rate > 0.0) {\n    double drop = (decision_rate / (*ref_decision_rate));\n    rate_trigger = (drop <= 0.95);\n  }\n\n  if (glue_trigger && rate_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 310, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1058}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e6224fec819092f148545e4d13f9", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "1eb22606e675632e0e805bc97593aa21", "body": {"id": "resp_0e4c4cd64b35c58a006921e5d2436c8197b31f1a583acbf70f", "object": "response", "created_at": 1763829202, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0e4c4cd64b35c58a006921e5d289308197a345afc8494b42f7", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict limit trigger (highest priority)\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // In stable phase, skip glue/decision checks.\n  if (solver->stable)\n    return false;\n\n  // Adaptive Glue-Decay Decision Rate logic:\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = solver->averages[solver->stable].decision_rate.value;\n  const double last_decision_rate = solver->restart_last_decision_rate;\n\n  const double glue_threshold = slow_glue + 2.0;\n  const double decision_rate_threshold = 0.95 * last_decision_rate;\n\n  bool glue_trigger = fast_glue > glue_threshold;\n  bool decision_rate_trigger = decision_rate <= decision_rate_threshold;\n\n  if (glue_trigger && decision_rate_trigger)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 252, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1000}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e62244208190a70fa60e36748f1c", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "6070c0763d9e8f8bfb6d7e3101758eac", "body": {"id": "resp_0c0fa465631d906c006921e5d4b64c8193b3262a87eed0641e", "object": "response", "created_at": 1763829204, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0c0fa465631d906c006921e5d4ee0c8193b7812c2a8cb9b36d", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n    assert(solver->unassigned);\n    if (!GET_OPTION(restart))\n        return false;\n    if (!solver->level)\n        return false;\n\n    // Always trigger restart if conflict limit is reached (highest priority)\n    if (CONFLICTS >= solver->limits.restart.conflicts)\n        return true;\n\n    // If in stable mode, skip glue/decision checks\n    if (solver->stable)\n        return false;\n\n    // Get glue and decision rate moving averages\n    const double fast_glue = AVERAGE(fast_glue);\n    const double slow_glue = AVERAGE(slow_glue);\n    const double decision_rate = AVERAGE(decision_rate);\n\n    // Retrieve last restart decision rate reference\n    double last_restart_decision_rate = solver->restart_decision_rate;\n\n    // Handle uninitialized last_restart_decision_rate (first call)\n    if (last_restart_decision_rate == 0.0) {\n        solver->restart_decision_rate = decision_rate;\n        last_restart_decision_rate = decision_rate;\n    }\n\n    // AGDRR glue and decision rate checks\n    bool glue_trigger = (fast_glue > slow_glue + 2.0);\n    bool decision_rate_trigger = (decision_rate <= 0.95 * last_restart_decision_rate);\n\n    if (glue_trigger && decision_rate_trigger) {\n        // Update reference for next epoch\n        solver->restart_decision_rate = decision_rate;\n        return true;\n    }\n\n    return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 327, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1075}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6921e62262a48190bd3e625428923856", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "aaf39c34417466630afc66d40e498e6a", "body": {"id": "resp_0fc722a0d892211c006921e5d78f488197be06f74049486e10", "object": "response", "created_at": 1763829207, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0fc722a0d892211c006921e5d804348197bec950d6aba12857", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // 1. Conflict limit: always highest priority.\n  if (CONFLICTS >= solver->limits.restart.conflicts)\n    return true;\n\n  // 2. In stable phase, skip glue/decision checks.\n  if (solver->stable)\n    return false;\n\n  // 3. Glue and decision rate conditions.\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // The reference value for decision_rate at last restart.\n  double reference_decision_rate = solver->restart.reference_decision_rate;\n\n  // Check glue threshold\n  const double glue_threshold = slow + 2.0;\n  bool glue_condition = (fast > glue_threshold);\n\n  // Check decision rate drop\n  double drop_limit = 0.95 * reference_decision_rate;\n  bool decision_condition = (decision_rate <= drop_limit);\n\n  // If both glue and decision rate trigger, restart.\n  if (glue_condition && decision_condition)\n    return true;\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 748, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 278, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1026}, "user": null, "metadata": {}}}, "error": null}
