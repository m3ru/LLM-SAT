{"id": "batch_req_692138c19c108190ab53afeb13405eca", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "0252c723d490a463152059fb0d898594", "body": {"id": "resp_0cf9b555e23a947800692138bc385c81908061b9617bd677f6", "object": "response", "created_at": 1763784892, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0cf9b555e23a947800692138bc89ac81908190dd78ebebb9db", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Check conflict limit condition (condition 3)\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Compute EWMAs for glue and decision rate\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n\n  // Condition 1: fast_glue_ewma >= slow_glue_ewma + 2.0\n  if (fast >= slow + 2.0) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    kissat_extremely_verbose(\n      solver,\n      \"adaptive restart: fast glue %g >= slow glue %g + 2.0 (%.2f)\",\n      fast, slow, slow + 2.0);\n    return true;\n  }\n\n  // Fetch decision rate EWMA and previous value\n  const double dec_rate = solver->decision_rate_ewma;\n  const double prev_dec_rate = solver->previous_decision_rate_ewma;\n\n  // Condition 2: decision_rate_ewma < 0.8 * previous_decision_rate_ewma\n  if (dec_rate < 0.8 * prev_dec_rate) {\n    solver->previous_decision_rate_ewma = dec_rate;\n    kissat_extremely_verbose(\n      solver,\n      \"adaptive restart: decision rate ewma %g < 0.8 * previous %g (%.2f)\",\n      dec_rate, prev_dec_rate, 0.8 * prev_dec_rate);\n    return true;\n  }\n\n  // If stable mode, use reluctant restart as fallback (if enabled in options)\n  if (solver->stable)\n    return kissat_reluctant_triggered(&solver->reluctant);\n\n  // No restart triggered\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 453, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1089}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c19c9081909d30717786afd8f1", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "a4770f0395b210019d2a40b4fd4d7657", "body": {"id": "resp_0b893474962f4a3b00692138802c2c81949bf0b41e31e78dbe", "object": "response", "created_at": 1763784832, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0b893474962f4a3b0069213880a7d48194823904bbae11ee79", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Condition 1: fast_glue_ewma >= slow_glue_ewma + 2.0\n  const double fast_glue_ewma = AVERAGE (fast_glue);\n  const double slow_glue_ewma = AVERAGE (slow_glue);\n  const double glue_gap = 2.0;\n  if (fast_glue_ewma >= slow_glue_ewma + glue_gap) {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive hybrid restart: fast_glue_ewma %g >= slow_glue_ewma %g + %g\",\n      fast_glue_ewma, slow_glue_ewma, glue_gap);\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Condition 2: decision_rate_ewma < 0.8 * previous_decision_rate_ewma\n  const double rate_drop_factor = 0.8;\n  if (solver->decision_rate_ewma < rate_drop_factor * solver->previous_decision_rate_ewma) {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive hybrid restart: decision_rate_ewma %g < %.2f * previous_decision_rate_ewma %g\",\n      solver->decision_rate_ewma, rate_drop_factor, solver->previous_decision_rate_ewma);\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Condition 3: stats.conflicts >= restart_conflict_limit\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    kissat_extremely_verbose (\n      solver,\n      \"adaptive hybrid restart: conflicts %ld >= restart_conflict_limit %ld\",\n      CONFLICTS, solver->limits.restart.conflicts);\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 471, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1107}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c196a881909457c8913346bd59", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "afb88b025fc696f2691892cd9f24de69", "body": {"id": "resp_09df137245f1fa6900692138bc4dd08196aa1ad98296c1ccc8", "object": "response", "created_at": 1763784892, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_09df137245f1fa6900692138bc9af481968339ead85a053f09", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Condition 3: Conflict limit\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Condition 1: Glue gap\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n  if (fast >= slow + 2.0) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    kissat_extremely_verbose (solver,\n      \"restarting: fast glue (%.2f) >= slow glue (%.2f) + 2.0\", fast, slow);\n    return true;\n  }\n\n  // Condition 2: Decision rate drops\n  if (solver->decision_rate_ewma < 0.8 * solver->previous_decision_rate_ewma) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    kissat_extremely_verbose (solver,\n      \"restarting: decision rate ewma (%.4f) < 0.8 * previous ewma (%.4f)\",\n      solver->decision_rate_ewma, solver->previous_decision_rate_ewma / 0.8);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 339, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 975}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c1af648190b14abea7999382c0", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "a364e6f7c7019401a38cbe55c2d1e9fd", "body": {"id": "resp_09d32e1ea31235fb00692138bc40a4819389c570069400f174", "object": "response", "created_at": 1763784892, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_09d32e1ea31235fb00692138bc94d08193898b8b1d8f6567f9", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver)\n{\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Condition 3: Conflict limit trigger\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n\n  // Condition 1: Glue gap trigger\n  if (fast >= slow + 2.0) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    kissat_extremely_verbose(\n      solver,\n      \"Restart: fast glue (%.2f) >= slow glue (%.2f) + 2.0 [%.2f]\",\n      fast, slow, slow + 2.0);\n    return true;\n  }\n\n  // Condition 2: Decision rate drop trigger\n  const double prev_decision_rate = solver->previous_decision_rate_ewma;\n  const double curr_decision_rate = solver->decision_rate_ewma;\n  if (curr_decision_rate < 0.8 * prev_decision_rate) {\n    solver->previous_decision_rate_ewma = curr_decision_rate;\n    kissat_extremely_verbose(\n      solver,\n      \"Restart: decision rate dropped (%.4f < 0.8 * %.4f = %.4f)\",\n      curr_decision_rate, prev_decision_rate, 0.8 * prev_decision_rate);\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 371, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1007}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c1a6d8819098e8d721d2fde611", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "c9d70b8100f06b1d83c44614fee8c11c", "body": {"id": "resp_0f37bd3eb0b9bbf0006921388041d0819391b8f77ebd9ebec0", "object": "response", "created_at": 1763784832, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0f37bd3eb0b9bbf000692138808b5c8193bf9e1248ecede337", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n\n  if (!GET_OPTION (restart))\n    return false;\n\n  if (!solver->level)\n    return false;\n\n  // Condition 3: Stats.conflicts >= restart_conflict_limit\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Only apply adaptive policy if at decision level >= 1\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n\n  // Condition 1: fast_glue_ewma >= slow_glue_ewma + 2.0\n  if (fast >= slow + 2.0) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    kissat_extremely_verbose (solver,\n      \"adaptive restart: fast_glue_ewma(%g) >= slow_glue_ewma(%g) + 2.0\", fast, slow);\n    return true;\n  }\n\n  // Condition 2: decision_rate_ewma < 0.8 * previous_decision_rate_ewma\n  const double rate = solver->decision_rate_ewma;\n  const double prev_rate = solver->previous_decision_rate_ewma;\n  if (rate < 0.8 * prev_rate) {\n    solver->previous_decision_rate_ewma = rate;\n    kissat_extremely_verbose (solver,\n      \"adaptive restart: decision_rate_ewma(%g) < 0.8 * previous_decision_rate_ewma(%g)\", rate, prev_rate);\n    return true;\n  }\n\n  // No restart condition met\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 393, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1029}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c193988190a9edb4334031b6dc", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "5503c3b2f9b3e0979a96cebf94b5ea8f", "body": {"id": "resp_0421a82ee3d7e22800692138bc37508193867b9ea3384b7b36", "object": "response", "created_at": 1763784892, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0421a82ee3d7e22800692138bc88348193a84e662f9fed448f", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Retrieve current stats and EWMA values\n  const double fast_glue = AVERAGE (fast_glue);\n  const double slow_glue = AVERAGE (slow_glue);\n  const double decision_rate = AVERAGE (decision_rate);\n\n  // Retrieve previous decision rate EWMA (use a solver field for this)\n  double prev_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Retrieve conflict restart limit\n  const uint64_t conflict_limit = solver->limits.restart.conflicts;\n\n  // Condition 1: Glue gap\n  if (fast_glue >= slow_glue + 2.0) {\n    solver->previous_decision_rate_ewma = decision_rate;\n    kissat_extremely_verbose (solver,\n      \"adaptive restart: fast_glue %.2f >= slow_glue %.2f + 2.0 (%.2f)\",\n      fast_glue, slow_glue, slow_glue + 2.0);\n    return true;\n  }\n\n  // Condition 2: Decision rate drop\n  if (decision_rate < 0.8 * prev_decision_rate) {\n    solver->previous_decision_rate_ewma = decision_rate;\n    kissat_extremely_verbose (solver,\n      \"adaptive restart: decision_rate %.4f < 0.8 * previous_decision_rate %.4f\",\n      decision_rate, prev_decision_rate);\n    return true;\n  }\n\n  // Condition 3: Conflict limit reached\n  if (CONFLICTS >= conflict_limit) {\n    solver->previous_decision_rate_ewma = decision_rate;\n    kissat_extremely_verbose (solver,\n      \"adaptive restart: conflicts %\" PRIu64 \" >= restart limit %\" PRIu64,\n      CONFLICTS, conflict_limit);\n    return true;\n  }\n\n  // No restart condition met\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 437, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1073}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c19fb08190933ff8a49bbf6c93", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "1fe29d52e02ed29284114b9826e6d814", "body": {"id": "resp_0700b33af243f3a300692138850938819485ada327f7171086", "object": "response", "created_at": 1763784837, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0700b33af243f3a3006921388560208194bc257155c6406879", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  // Option enabled?\n  if (!GET_OPTION(restart))\n    return false;\n\n  // Only at non-root level\n  if (!solver->level)\n    return false;\n\n  // Get the conflict limit for restarts\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  // EWMA averages for glue\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n\n  // Decision rate EWMA and previous value\n  const double decision_rate = AVERAGE(decision_rate);\n  double *previous_decision_rate_ptr = &solver->previous_decision_rate_ewma;\n  const double previous_decision_rate = *previous_decision_rate_ptr;\n\n  // Conflict limit for restart\n  const uint64_t restart_conflict_limit = solver->limits.restart.conflicts;\n\n  bool triggered = false;\n\n  // 1. GLUE GAP: fast_glue >= slow_glue + 2.0\n  if (fast >= slow + 2.0) {\n    kissat_extremely_verbose(solver,\n      \"restart: fast_glue %.2f >= slow_glue %.2f + 2.0 (%.2f)\", fast, slow, slow + 2.0);\n    triggered = true;\n  }\n  // 2. DECISION RATE DROP: decision_rate < 0.8 * previous_decision_rate\n  else if (decision_rate < 0.8 * previous_decision_rate) {\n    kissat_extremely_verbose(solver,\n      \"restart: decision_rate %.4f < 0.8 * previous_decision_rate %.4f (%.4f)\",\n      decision_rate, previous_decision_rate, 0.8 * previous_decision_rate);\n    triggered = true;\n  }\n  // 3. CONFLICT LIMIT: stats.conflicts >= restart_conflict_limit\n  else if (CONFLICTS >= restart_conflict_limit) {\n    kissat_extremely_verbose(solver,\n      \"restart: CONFLICTS %\" PRIu64 \" >= restart_conflict_limit %\" PRIu64,\n      CONFLICTS, restart_conflict_limit);\n    triggered = true;\n  }\n\n  if (triggered) {\n    *previous_decision_rate_ptr = decision_rate;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 513, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1149}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c1cc108190b5e2067a432c2d88", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "8e6288024f3b2ca08aa44f0c67f0985b", "body": {"id": "resp_034c70e4f3c7333b00692138bc42688196a75f3ed144e08dce", "object": "response", "created_at": 1763784892, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_034c70e4f3c7333b00692138bc8d408196916687804b8ec0f9", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Condition 3: stats.conflicts >= restart_conflict_limit\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Obtain EWMA values for glue and decision rate\n  const double fast_glue_ewma = AVERAGE (fast_glue);\n  const double slow_glue_ewma = AVERAGE (slow_glue);\n  const double decision_rate_ewma = solver->decision_rate_ewma;\n  const double previous_decision_rate_ewma = solver->previous_decision_rate_ewma;\n\n  // Condition 1: Glue gap\n  if (fast_glue_ewma >= slow_glue_ewma + 2.0) {\n    solver->previous_decision_rate_ewma = decision_rate_ewma;\n    return true;\n  }\n\n  // Condition 2: Decision rate drop\n  if (decision_rate_ewma < 0.8 * previous_decision_rate_ewma) {\n    solver->previous_decision_rate_ewma = decision_rate_ewma;\n    return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 307, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 943}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c1a6388190864c50ead27ccff7", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "d704774e8ef275edf92fcbd385c03665", "body": {"id": "resp_0763214705f8eac0006921388901888195ae3ea13286ac3f73", "object": "response", "created_at": 1763784841, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0763214705f8eac0006921388953a08195aafed43c617f64f7", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Fetch EWMA values for glue and decision rate\n  const double fast_glue = AVERAGE(fast_glue);\n  const double slow_glue = AVERAGE(slow_glue);\n  const double decision_rate = AVERAGE(decision_rate);\n\n  // Retrieve previous decision rate EWMA from solver struct (must be defined)\n  double previous_decision_rate = solver->previous_decision_rate_ewma;\n\n  // Conflict-based restart limit\n  if (solver->stats.conflicts >= solver->limits.restart.conflicts) {\n    // Update previous_decision_rate_ewma on restart\n    solver->previous_decision_rate_ewma = decision_rate;\n    kissat_extremely_verbose(solver,\n      \"restart: conflict limit reached (conflicts=%\" PRIu64 \", limit=%\" PRIu64 \")\",\n      solver->stats.conflicts, solver->limits.restart.conflicts);\n    return true;\n  }\n\n  // 1. Glue gap condition: fast >= slow+2.0\n  if (fast_glue >= slow_glue + 2.0) {\n    solver->previous_decision_rate_ewma = decision_rate;\n    kissat_extremely_verbose(solver,\n      \"restart: fast_glue_ewma=%.2f >= slow_glue_ewma=%.2f + 2.0\", fast_glue, slow_glue);\n    return true;\n  }\n\n  // 2. Decision rate drop condition: decision_rate_ewma < 0.8 * previous_decision_rate_ewma\n  if (decision_rate < 0.8 * previous_decision_rate) {\n    solver->previous_decision_rate_ewma = decision_rate;\n    kissat_extremely_verbose(solver,\n      \"restart: decision_rate_ewma=%.6f < 0.8 * previous_decision_rate_ewma=%.6f\",\n      decision_rate, previous_decision_rate);\n    return true;\n  }\n\n  // No restart condition met\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 470, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 1106}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_692138c1a4f48190863b115e876601af", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "e67a9ade4bac5aafe61860e838ffd978", "body": {"id": "resp_0a261ceb3705006e006921388048388193837df293ed082a32", "object": "response", "created_at": 1763784832, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4.1-2025-04-14", "output": [{"id": "msg_0a261ceb3705006e00692138808fd481938a6617770c8deeaa", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting (kissat *solver) {\n  assert (solver->unassigned);\n  if (!GET_OPTION (restart))\n    return false;\n  if (!solver->level)\n    return false;\n\n  // Conflict limit condition (Condition 3)\n  if (CONFLICTS >= solver->limits.restart.conflicts) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Get glue EWMAs\n  const double fast = AVERAGE (fast_glue);\n  const double slow = AVERAGE (slow_glue);\n\n  // Condition 1: glue gap\n  if (fast >= slow + 2.0) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // Condition 2: decision rate drop\n  if (solver->decision_rate_ewma < 0.8 * solver->previous_decision_rate_ewma) {\n    solver->previous_decision_rate_ewma = solver->decision_rate_ewma;\n    return true;\n  }\n\n  // No condition met, do not restart\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 636, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 258, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 894}, "user": null, "metadata": {}}}, "error": null}
